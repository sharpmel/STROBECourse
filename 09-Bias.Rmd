---
title: "09-Bias"
author: "Melissa K Sharp"
delete_merged_file: true
site: bookdown::bookdown_site
output:
  bookdown::gitbook:
    number_sections: false 
    includes: 
      after_body: disqus.html
      in_header: analytics.html 
bibliography: bibliography.bib
csl: apa-annotated.csl
link-citations: yes
edit: https://github.com/sharpmel/STROBECourse
---

# Methods: Bias (9) 
> The items from STROBE state that you should report:  
- Describe any efforts to address potential sources of bias  
</br> 

**Some key items to consider adding:**  
- Describe the nature and magnitude of any potential biases and explain what approach was used to deal with these (e.g., discovery, ascertainment, selection, information, etc.)   
-	For quantitative outcome variables, specify if any investigation of potential bias resulting from pharmacotherapy was undertaken   
- Report how bias in dietary or nutritional assessment was addressed, e.g., misreporting, changes in habits as a result of being measured, or data imputation from other sources    
</br> 

## Explanation  
> Biased studies produce results that differ systematically from the truth (see also [box 3][Box 3. Bias]). It is important for a reader to know what measures were taken during the conduct of a study to reduce the potential of bias. Ideally, investigators carefully consider potential sources of bias when they plan their study. At the stage of reporting, we recommend that authors always assess the likelihood of relevant biases. Specifically, the direction and magnitude of bias should be discussed and, if possible, estimated. For instance, in casecontrol studies information bias can occur, but may be reduced by selecting an appropriate control group, as in the first example.[@phillips2002] Differences in the medical surveillance of participants were a problem in the second example.[@pasquale2006]  
</br>
Consequently, the authors provide more detail about the additional data they collected to tackle this problem. When investigators have set up quality control programs for data collection to counter a possible “drift” in measurements of variables in longitudinal studies, or to keep variability at a minimum when multiple observers are used, these should be described.  
</br>
Unfortunately, authors often do not address important biases when reporting their results. Among 43 case-control and cohort studies published from 1990 to 1994 that investigated the risk of second cancers in patients with a history of cancer, medical surveillance bias was mentioned in only 5 articles.[@craig1999] A survey of reports of mental health research published during 1998 in 3 psychiatric journals found that only 13% of 392 articles mentioned response bias.[@rogler2001] A survey of cohort studies in stroke research found that 14 of 49 (28%) articles published from 1999 to 2003 addressed potential selection bias in the recruitment of study participants and 35 (71%) mentioned the possibility that any type of bias may have affected results.5 [@vandenbroucke2007]

## Examples  
- Example 1.  
“In most case-control studies of suicide, the control group comprises living individuals but we decided to have a control group of people who had died of other causes (…). With a control group of deceased individuals, the sources of information used to assess risk factors are informants who have recently experienced the death of a family member or close associate - and are therefore more comparable to the sources of information in the suicide group than if living controls were used” [@phillips2002].  
</br>
- Example 2.  
“Detection bias could influence the association between Type 2 diabetes mellitus (T2DM) and primary open-angle glaucoma (POAG) if women with T2DM were under closer ophthalmic surveillance than women without this condition. We compared the mean number of eye examinations reported by women with and without diabetes. We also recalculated the relative risk for POAG with additional control for covariates associated with more careful ocular surveillance (a self-report of cataract, macular degeneration, number of eye examinations, and number of physical examinations).” [@pasquale2006; @vandenbroucke2007]

</br> 

## Box 3. Bias
Bias is a systematic deviation of a study's result from a true value. Typically, it is introduced during the design or implementation of a study and cannot be remedied later. Bias and confounding are not synonymous. Bias arises from flawed information or subject selection so that a wrong association is found. Confounding produces relations that are factually right, but that cannot be interpreted causally because some underlying, unaccounted for factor is associated with both exposure and outcome (see Box 5). Also, bias needs to be distinguished from random error, a deviation from a true value caused by statistical fluctuations (in either direction) in the measured data. Many possible sources of bias have been described and a variety of terms are used [@murphy1976; @sackett1979]. We find two simple categories helpful: information bias and selection bias.  
</br>
<i>Information bias</i> occurs when systematic differences in the completeness or the accuracy of data lead to differential misclassification of individuals regarding exposures or outcomes. For instance, if diabetic women receive more regular and thorough eye examinations, the ascertainment of glaucoma will be more complete than in women without diabetes (see [item 9][Methods: Bias (9) ]) [@pasquale2006]. Patients receiving a drug that causes non-specific stomach discomfort may undergo gastroscopy more often and have more ulcers detected than patients not receiving the drug – even if the drug does not cause more ulcers. This type of information bias is also called ‘detection bias' or ‘medical surveillance bias'. One way to assess its influence is to measure the intensity of medical surveillance in the different study groups, and to adjust for it in statistical analyses. In case-control studies information bias occurs if cases recall past exposures more or less accurately than controls without that disease, or if they are more or less willing to report them (also called ‘recall bias'). ‘Interviewer bias' can occur if interviewers are aware of the study hypothesis and subconsciously or consciously gather data selectively [@johannes1997]. Some form of blinding of study participants and researchers is therefore often valuable.  
</br>
Selection bias may be introduced in case-control studies if the probability of including cases or controls is associated with exposure. For instance, a doctor recruiting participants for a study on deep-vein thrombosis might diagnose this disease in a woman who has leg complaints and takes oral contraceptives. But she might not diagnose deep-vein thrombosis in a woman with similar complaints who is not taking such medication. Such bias may be countered by using cases and controls that were referred in the same way to the diagnostic service [@bloemenkamp1999]. Similarly, the use of disease registers may introduce selection bias: if a possible relationship between an exposure and a disease is known, cases may be more likely to be submitted to a register if they have been exposed to the suspected causative agent [@feinstein1985]. ‘Response bias' is another type of selection bias that occurs if differences in characteristics between those who respond and those who decline participation in a study affect estimates of prevalence, incidence and, in some circumstances, associations. In general, selection bias affects the internal validity of a study. This is different from problems that may arise with the selection of participants for a study in general, which affects the external rather than the internal validity of a study (also see [item 21][Discussion: Generalizability (21)]).[@vandenbroucke2007]
</br></br>

## Field-specific guidance  
**Seroepidemiologic studies for influenza [@horby2017]**  
-	If relevant, describe efforts to control for the potential effect of immunization on estimates of outcomes  
</br>

## Resources  
Do you know of any good guidance or resources related to this item? Suggest them via comments below, [Twitter](https://twitter.com/sharpmelk), [GitHub](https://github.com/sharpmel/STROBECourse), or [e-mail](mailto:melissaksharp@gmail.com).  
-Boffetta, P. (1995). Sources of bias, effect of confounding in the application of biomarkers to epidemiological studies. Toxicology Letters, 77(1), 235–238. https://doi.org/10.1016/0378-4274(95)03301-7 [@boffetta1995]  
- Centre for Evidence-Based Medicine. (2017). Catalogue of Bias. In Catalog of Bias. https://catalogofbias.org/ [@cebm2017]  
</br> 