---
title: "10-StudySize"
author: "Melissa K Sharp"
delete_merged_file: true
site: bookdown::bookdown_site
output:
  bookdown::gitbook:
    number_sections: false 
    includes: 
      after_body: disqus.html 
bibliography: bibliography.bib
csl: apa-annotated.csl
link-citations: yes
edit: https://github.com/sharpmel/STROBECourse
---

# Methods: Study Size (10)
> The items from STROBE state that you should report:   
-	Explain how the study size was arrived at  

</br> 
The sample size needed for a study depends on many factors including the size of the model, distribution of the variables, amount of missing data, reliability of the variables, and strength of the relationships among the variables.  
</br>

**Some key items to consider adding:**  
-	Any unique restrictions placed on the study sample size  
- Different determinants of sample size for different levels of organization (e.g., parent and offspring, family unit, etc.)  
- How non-independence of measurements was incorporated into sample-size considerations  
-	The parameters, assumptions, methods, and effect size justification of the sample size calculation  
</br>

## Examples  
Example 1.  
“The number of cases in the area during the study period determined the sample size” [@yadon2003; @vandenbroucke2007].  
</br>  
Example 2.  
“A survey of postnatal depression in the region had documented a prevalence of 19.8%. Assuming depression in mothers with normal weight children to be 20% and an odds ratio of 3 for depression in mothers with a malnourished child we needed 72 case-control sets (one case to one control) with an 80% power and 5% significance” [@anoop2004; @vandenbroucke2007].
</br>

## Explanation  
> A study should be large enough to obtain a point estimate with a sufficiently narrow confidence interval to meaningfully answer a research question. Large samples are needed to distinguish a small association from no association. Small studies often provide valuable information, but wide confidence intervals may indicate that they contribute less to current knowledge in comparison with studies providing estimates with narrower confidence intervals. Also, small studies that show ‘interesting’ or ‘statistically significant’ associations are published more frequently than small studies that do not have ‘significant’ findings. While these studies may provide an early signal in the context of discovery, readers should be informed of their potential weaknesses.  
</br>
The importance of sample size determination in observational studies depends on the context. If an analysis is performed on data that were already available for other purposes, the main question is whether the analysis of the data will produce results with sufficient statistical precision to contribute substantially to the literature, and sample size considerations will be informal. Formal, a priori calculation of sample size may be useful when planning a new study [@carlin2002; @rigby1998]. Such calculations are associated with more uncertainty than implied by the single number that is generally produced. For example, estimates of the rate of the event of interest or other assumptions central to calculations are commonly imprecise, if not guesswork [@schulz2005]. The precision obtained in the final analysis can often not be determined beforehand because it will be reduced by inclusion of confounding variables in multivariable analyses [@drescher1990], the degree of precision with which key variables can be measured [@devine1998], and the exclusion of some individuals.  
</br>
Few epidemiological studies explain or report deliberations about sample size.[@pocock2004; @tooth2005] We encourage investigators to report pertinent formal sample size calculations if they were done. In other situations they should indicate the considerations that determined the study size (eg, a fixed available sample, as in the first example above). If the observational study was stopped early when statistical significance was achieved, readers should be told. Do not bother readers with post hoc justifications for study size or retrospective power calculations.[@schulz2005] From the point of view of the reader, confidence intervals indicate the statistical precision that was ultimately obtained. It should be realized that confidence intervals reflect statistical uncertainty only, and not all uncertainty that may be present in a study (see [item 20][Discussion: Interpretation (20)]).[@vandenbroucke2007]
</br>

## Box 4. Grouping  
There are several reasons why continuous data may be grouped [@altman2005]. When collecting data it may be better to use an ordinal variable than to seek an artificially precise continuous measure for an exposure based on recall over several years. Categories may also be helpful for presentation, for example to present all variables in a similar style, or to show a dose-response relationship.  
</br>
Grouping may also be done to simplify the analysis, for example to avoid an assumption of linearity. However, grouping loses information and may reduce statistical power [@cohen1983] especially when dichotomization is used [@royston2006; @maccallum2002; @zhao1992]. If a continuous confounder is grouped, residual confounding may occur, whereby some of the variable's confounding effect remains unadjusted for (see [Box 5][Box 5. Confounding]) [@becher1992; @cochran1968]. Increasing the number of categories can diminish power loss and residual confounding, and is especially appropriate in large studies. Small studies may use few groups because of limited numbers.  
</br>
Investigators may choose cut-points for groupings based on commonly used values that are relevant for diagnosis or prognosis, for practicality, or on statistical grounds. They may choose equal numbers of individuals in each group using quantiles [@clayton1993]. On the other hand, one may gain more insight into the association with the outcome by choosing more extreme outer groups and having the middle group(s) larger than the outer groups [@cox1957]. In case-control studies, deriving a distribution from the control group is preferred since it is intended to reflect the source population. Readers should be informed if cut-points are selected post hoc from several alternatives. In particular, if the cut-points were chosen to minimise a P value the true strength of an association will be exaggerated [@altman1994].  
</br>
When analysing grouped variables, it is important to recognise their underlying continuous nature. For instance, a possible trend in risk across ordered groups can be investigated. A common approach is to model the rank of the groups as a continuous variable. Such linearity across group scores will approximate an actual linear relation if groups are equally spaced (e.g., 10 year age groups) but not otherwise. Il'yasova et al [@ilyasova2005] recommend publication of both the categorical and the continuous estimates of effect, with their standard errors, in order to facilitate meta-analysis, as well as providing intrinsically valuable information on dose-response. One analysis may inform the other and neither is assumption-free. Authors often ignore the ordering and consider the estimates (and P values) separately for each category compared to the reference category. This may be useful for description, but may fail to detect a real trend in risk across groups. If a trend is observed, a confidence interval for a slope might indicate the strength of the observation.  
</br>

## Field-specific guidance  
**Seroepidemiologic studies for influenza [@horby2017]**  
- Describe the baseline estimated seroprevalence at given antibody titers or incidence of infection and cite published literature to support these estimates  

</br>
## Resources  
Do you know of any good guidance or resources related to this item? Suggest them via comments below, [Twitter](https://twitter.com/sharpmelk), [GitHub](https://github.com/sharpmel/STROBECourse), or [e-mail](mailto:melissaksharp@gmail.com).  
Coppock, A. Power Calculator (Shiny App). Retrieved January 27, 2020, from https://egap.shinyapps.io/Power_Calculator/ [@coppockShiny]