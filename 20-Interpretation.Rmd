---
title: "20-Interpretation"
author: "Melissa K Sharp"
delete_merged_file: true
site: bookdown::bookdown_site
output:
  bookdown::gitbook:
    number_sections: false 
    includes: 
      after_body: disqus.html
bibliography: bibliography.bib
csl: apa-annotated.csl
link-citations: yes
edit: https://github.com/sharpmel/STROBECourse
---

# Discussion: Interpretation (20)  
> The items from STROBE state that you should report:   
-	Give a cautious overall interpretation of results considering objectives, limitations, multiplicity of analyses, results from similar studies, and other relevant evidence  

</br> 
**Some key items to consider adding:**   
- Give an interpretation of results in terms of a priori biological plausibility  

</br> 

## Explanation  
> The heart of the discussion section is the interpretation of a study’s results. Over-interpretation is common and human: even when we try hard to give an objective assessment, reviewers often rightly point out that we went too far in some respects. When interpreting results, authors should consider the nature of the study on the discovery to verification continuum and potential sources of bias, including loss to follow-up and non-participation (see also items [9][Methods: Bias (9)], [12][Methods: Statistical Methods (12)] and [19][Discussion: Limitations (19)]). Due consideration should be given to confounding ([item 16a][Explanation 16a]), the results of relevant sensitivity analyses, and to the issue of multiplicity and subgroup analyses ([item 17][Results: Other Analyses (17)]). Authors should also consider residual confounding due to unmeasured variables or imprecise measurement of confounders. For example, socioeconomic status (SES) is associated with many health outcomesand often differs between groups being compared. Variables used to measure SES (income, education, or occupation) are surrogates for other undefined and unmeasured exposures, and the true confounder will by definition be measured with error. [@kaufman1997] Authors should address the real range of uncertainty in estimates, which is larger than the statistical uncertainty reflected in confidence intervals. The latter do not take into account other uncertainties that arise from a study’s design, implementation, and methods of measurement. [@greenland1990]  
</br>
To guide thinking and conclusions about causality, some may find criteria proposed by Bradford Hill in 1965 helpful. [@hill1965] How strong is the association with the exposure? Did it precede the onset of disease? Is the association consistently observed in different studies and settings? Is there supporting evidence from experimental studies, including laboratory and animal studies? How specific is the exposure’s putative effect, and is there a dose-response relationship? Is the association biologically plausible? These criteria should not, however, be applied mechanically. For example, some have argued that relative risks below 2 or 3 should be ignored.[@taubes1995; @temple1999] This is a reversal of the point by Cornfield et al about the strength of large relative risks (see [item 12b][Explanation 12b]). [@cornfield1959] Although a causal effect is more likely with a relative risk of 9, it does not follow that one below 3 is necessarily spurious. For instance, the small increase in the risk of childhood leukemia after intrauterine irradiation is credible because it concerns an adverse effect of a medical procedure for which no alternative explanations are obvious.[@greenberg1985] Moreover, the carcinogenic effects of radiation are well established. The doubling in the risk of ovarian cancer associated with eating 2 to 4 eggs per week is not immediately credible, since dietary habits are associated with a large number of lifestyle factors as well as SES. [@kushi1999] In contrast, the credibility of much debated epidemiologic findings of a difference in thrombosis risk between different types of oral contraceptives was greatly enhanced by the differences in coagulation found in a randomized cross-over trial. [@kemmeren2004] A discussion of the existing external evidence, from different types of studies, should always be included, but may be particularly important for studies reporting small increases in risk. Further, authors should put their results in context with similar studies and explain how the new study affects the existing body of evidence, ideally by referring to a systematic review.
</br></br>

## Example  
- “Any explanation for an association between death from myocardial infarction and use of second generation oral contraceptives must be conjectural. There is no published evidence to suggest a direct biologic mechanism, and there are no other epidemiologic studies with relevant results. (. . .) The increase in absolute risk is very small and probably applies predominantly to smokers. Due to the lack of corroborative evidence, and because the analysis is based on relatively small numbers, more evidence on the subject is needed. We would not recommend any change in prescribing practice on the strength of these results.” [@dunn2001; @vandenbroucke2007] 

</br></br> 

## Field-specific guidance    
**Seroepidemiologic studies for influenza [@horby2017]**    
- Discuss the interpretation of the results in the context of known or potential cross-reactivity </br>  

**Nutritional data [@lachat2016]**  
- Report the nutritional relevance of the ﬁndings, given the complexity of diet or nutrition as an exposure</br>   

## Resources  
Do you know of any good guidance or resources related to this item? Suggest them via comments below, [Twitter](https://twitter.com/sharpmelk), [GitHub](https://github.com/sharpmel/STROBECourse), or [e-mail](mailto:melissaksharp@gmail.com).
</br> 