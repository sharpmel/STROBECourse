[
["index.html", "Strengthening the Reporting of Observational Studies in Epidemiology STROBE (STROBE) Educational Expansion Introduction Structure Audience Content", " Strengthening the Reporting of Observational Studies in Epidemiology STROBE (STROBE) Educational Expansion Melissa K Sharp 2020-05-09 Introduction The purpose of this site is to create a public, open-source repository for epidemiological research methods and reporting skills for observational studies. Epidemiology, the study of diseases and population health, is a broad field with ever-changing methods and often heated debates about proper designs, analyses, and approaches. Therefore, we think it is important that there is a place where epidemiologists can share their knowledge in an open and transparent manner. Drawing inspiration from the #epitwitter community, the Open Science Massive Online Course, and Data Methods, we hope that this will become a living site which can be used and modified by the epidemiology community and those interested in sharing epidemiological knowledge in accessible ways. For a quick peek into how this site works and how you can contribute, please check out the Frequently Asked Questions page. This site is uses the R Bookdown package, which is built using R Markdown. All content is stored in the GitHub repository of Melissa Sharp, a doctoral student who worked on observational research methods. Please contact her if you have any comments, questions, or concerns. Structure We aim to be as inclusive as possible but are structuring this site on the Strengthening the Reporting of Observational studies in Epidemiology (STROBE) reporting guideline. STROBE was created in 2007 and is comprised of a 22-item checklist of essential items to report when discussing the results from a cohort, cross-sectional, or case-control study (Elm et al., 2007; Vandenbroucke et al., 2007). It has been endorsed by the International Commitee of Medcial Journal Editors and hundreds of journals and has spawned at least another 13 field- or method-specific extensions. (Benchimol et al., 2015; Cheng et al., 2016; Creinin &amp; Chen, 2016 ; Field et al., 2014; Gallo et al., 2012; Horby et al., 2017; Hornell et al., 2017; Lachat et al., 2016; Little et al., 2009; O’Connor et al., 2016; Tacconelli et al., 2016; White et al., 2015; Zavada et al., 2014) Figure 1: STROBE Checklist STROBE and this book follows the IMRaD (Introduction, Methods, Results, and Discussion) style of reporting research. The content from STROBE’s Explanation and Elaboration document (Vandenbroucke et al., 2007) will be included in this site as it explains why each item on the STROBE checklist is important and it gives examples of “good reporting”. Additional information will be supplied from the dissertation of Melissa Sharp and the projects contained within it – particularly results from a qualitative assessment of the content in the STROBE Extensions. (Sharp et al., 2018) Hopefully, over time, others will contribute additional examples and resources related to each STROBE item. Content is designed in a modular format that is aligned with the design of the STROBE Checklist. - If you are familiar with epidemiological research methods and STROBE, you can pick and choose what items to explore. - Otherwise, if you are unexperienced, you can follow the structure in a more linear fashion, beginning with an introduction on the concept of reporting guidelines and their use. Audience The content in this book will appeal to those who work in observational research, need a refresher on certain epidemiological topics, or want to improve their scientific writing skills. Some baseline understanding of clinical or public health research may be helpful though since using STROBE should imply that you have or are working in health research. Content We hope to help you develop your understanding of study designs, data collection, statistical analysis, and interpretation of results. This site will not cover key aspects of the conduct of research, such as the skills needed for personal interactions with patients and participants, detailed analytical skills, regulatory frameworks, nor science communication skills needed to disseminate your work to the general public. All are important areas influencing items covered in this course but the breadth is too great to go over each area in depth. Rather, we aim to provide supplementary information along the way that will help you explore and grow in these areas if you so wish. Funding Statement and Licensing This site is a project of the Methods in Research on Research (MiRoR) project, supported by the European Union’s Horizon 2020 research and innovation programme under the Marie Sklodowska-Curie grant agreement No 676207.The online version of this book is licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. References "],
["observational-studies.html", "Observational Studies Why STROBE? What is STROBE?", " Observational Studies Careful design and analysis of observational studies is essential because they are not structured to control for these external factors, thus they are especially prone to bias and confounding (Dreyer et al., 2010; Hemkens et al., 2018; Song &amp; Chung, 2010). In an ideal world, people would be able to use randomized control trials more often, however, sometimes it is simply unethical or impractical to conduct an RCT (Scales et al., 2005; Song &amp; Chung, 2010). For example, when investigating socioeconomic impacts on health or surgical procedures. Due to the complex design and conduct of observational studies, they have been deemed to be “the most necessary and difficult” studies to conduct (Harper, 2019). Observational studies are conducted in real-world settings and can investigate the impact of health policies on populations and explore the distribution of health outcomes across groups (Dreyer et al., 2010). RCTs simply cannot achieve these same results. Observational research also allows participants to be followed for longer periods of time meaning that one can evaluate changes in health outcomes throughout the lifespan. Furthermore, observational studies affordably provide a larger number of participants in comparison to RCTs (Dreyer et al., 2010). This allows investigations into differences between subgroups in the population (e.g., different age groups, disease subtypes) (Ligthelm et al., 2007). Given the breadth of topics that observational studies can cover, it is no surprise that it is the most common study design used in biomedical research (Funai et al., 2001). Why STROBE? Due to a high prevalence of observational studies in biomedical research, widespread poor reporting means that an enormous amount of the medical literature has issues. Research has shown that items concerning the methodology and results of observational studies are particularly poorly reported reported (Irani et al., 2018; Jeelani et al., 2014; Kim et al., 2012; Langan et al., 2010; Papathanasiou &amp; Zintzaras, 2010; Poorolajal J et al., 2011). Details about participants, data collection methods, and analyses are common problems. Missing details on how many people were eligible to participate, consented, and lost to follow-up questions the generalizability of results. Whereas, missing data, the reliability of the data collection instruments used, how the data was analyzed, and missing disclosures of funding sources can be worrying as motives for certain narratives or results may be hidden. Therefore, a reporting guideline for observational research is critically needed to reinforce replicability and reproducibility and instill greater confidence in the trustworthiness of results. What is STROBE? The STrengthening the Reporting of OBservational studies in Epidemiology (STROBE) Statement is a 22-item checklist that details the key information needed when reporting the results of an observational study (Elm et al., 2007) (Figure 1). It is also accompanied by an Explanation and Elaboration (E&amp;E) document that provides further details for each checklist item and gives examples of good reporting (Vandenbroucke et al., 2007). STROBE comes as a downloadable checklist. You can download a fillable Word checklist (or static pdf) on the STROBE website. There is also a Writing Aid Tool for Microsoft that you can download and install which includes the STROBE checklist within the software. For detailed background and guidance on STROBE you can read the Explanation and Elaboration (Vandenbroucke et al., 2007) article. Briefly put, STROBE does not dictate how to conduct research nor the specific order that items should be written in (only that they should be under the relevant IMRaD heading). Some items may not be applicable to your study, just state so and explain why. STROBE is not meant to be a “procedural straightjacket”, rather, think of it as a life jacket. Its structure may be helpful for study planing or peer review but it is not designed for that purpose. References "],
["intro-title-and-abstract-1.html", "Intro: Title and abstract (1) Explanation 1a Examples 1a Explanation 1b Example 1b Field-specific guidance Resources", " Intro: Title and abstract (1) The items from STROBE state that you should report: - Indicate the study’s design with a commonly used term in the title or the abstract; AND - Provide in the abstract, an informative and balanced summary of what was done and what was found (Vandenbroucke et al., 2007) First and foremost, thoughtful consideration must be given to the title of your work and the abstract. Based on which journal you plan on submitting your work to, they might provide restrictions on how many words you can use, so be as concise and unambiguous as possible. Try to be as objective as possible and frame your findings correctly. Although this is the first item in the checklist, some people find that it is the easiest to write these at or near the end of your work as it contains the key messages that you want to focus on. Some key items to consider adding: - The study design (e.g., cohort, cross-sectional, case-control). - Information about the data source (e.g., bibliometric, patient registry, etc.) - Information about the timing of data collection (e.g., longitudinal, date ranges) - The main results (e.g., “found high rates of x”, \" ) Explanation 1a Readers should be able to easily identify the design that was used from the title or abstract. An explicit, commonly used term for the study design also helps ensure correct indexing of articles in electronic databases.(Benson &amp; Hartz, 2000; Vandenbroucke et al., 2007) Examples 1a “Leukemia incidence among workers in the shoe and boot manufacturing industry: a case-control study” (Forand, 2004; Vandenbroucke et al., 2007) “The consumption of sugar-sweetened beverages was derived from 7 repeated FFQs administered between 1980 and 2002” (Fung et al., 2009; Hornell et al., 2017; Vandenbroucke et al., 2007) “Key finding/exposures” among/in “sample/population” during “time period of study/data collection” : “study design” “Study design” investigating “exposures” among “sample/population” during “time period of study/data collection” found “key findings” Explanation 1b The abstract provides key information that enables readers to understand a study and decide whether to read the article. Typical components include a statement of the research question, a short description of methods and results, and a conclusion (American Journal of Epidemiology, 2007). Abstracts should summarize key details of studies and should only present information that is provided in the article. We advise presenting key results in a numerical form that includes numbers of participants, estimates of associations and appropriate measures of variability and uncertainty (e.g., odds ratios with confidence intervals). We regard it insufficient to state only that an exposure is or is not significantly associated with an outcome. A series of headings pertaining to the background, design, conduct, and analysis of a study may help readers acquire the essential information rapidly (Haynes, 1990). Many journals require such structured abstracts, which tend to be of higher quality and more readily informative than unstructured summaries (Hartley &amp; Sydes, 1996; Taddio et al., 1994; Vandenbroucke et al., 2007). Example 1b Background: The expected survival of HIV-infected patients is of major public health interest. Objective: To estimate survival time and age-specific mortality rates of an HIV-infected population compared with that of the general population. Design: Population-based cohort study. Setting: All HIV-infected persons receiving care in Denmark from 1995 to 2005. Patients: Each member of the nationwide Danish HIV Cohort Study was matched with as many as 99 persons from the general population according to sex, date of birth, and municipality of residence. Measurements: The authors computed Kaplan–Meier life tables with age as the time scale to estimate survival from age 25 years. Patients with HIV infection and corresponding persons from the general population were observed from the date of the patient’s HIV diagnosis until death, emigration, or 1 May 2005. Results: 3990 HIV-infected patients and 379 872 persons from the general population were included in the study, yielding 22 744 (median, 5.8 y/person) and 2 689 287 (median, 8.4 years/person) person-years of observation. Three percent of participants were lost to follow-up. From age 25 years, the median survival was 19.9 years (95% CI, 18.5 to 21.3) among patients with HIV infection and 51.1 years (CI, 50.9 to 51.5) among the general population. For HIV-infected patients, survival increased to 32.5 years (CI, 29.4 to 34.7) during the 2000 to 2005 period. In the subgroup that excluded persons with known hepatitis C coinfection (16%), median survival was 38.9 years (CI, 35.4 to 40.1) during this same period. The relative mortality rates for patients with HIV infection compared with those for the general population decreased with increasing age, whereas the excess mortality rate increased with increasing age. Limitations: The observed mortality rates are assumed to apply beyond the current maximum observation time of 10 years. Conclusions: The estimated median survival is more than 35 years for a young person diagnosed with HIV infection in the late highly active antiretroviral therapy era. However, an ongoing effort is still needed to further reduce mortality rates for these persons compared with the general population (Lohse et al., 2007; Vandenbroucke et al., 2007) Field-specific guidance Infectious disease molecular epidemiology (Field et al., 2014) - The term molecular epidemiology should be applied to the study in the title or abstract and the keywords when molecular and epidemiological methods contribute substantially to the study Molecular epidemiology (Gallo et al., 2012) - State the use of speciﬁc biomarker(s) in the title and ⁄or in the abstract if they contribute substantially to the ﬁndings Nutritional data (Lachat et al., 2016) - State the dietary/nutritional assessment method(s) used in the title, abstract, or keywords Response-driven sampling (White et al., 2015) - Indicate “respondent-driven sampling” in the title or abstract Routinely collected health data (Benchimol et al., 2015) - The type of data used should be speciﬁed in the title or abstract. When possible, the name of the databases used should be included - If applicable, the geographic region and time frame within which the study took place should be reported in the title or abstract - If linkage between databases was conducted for the study, this should be clearly stated in the title or abstract Seroepidemiologic studies for influenza (Horby et al., 2017) - The term “seroepidemiologic,” “seroepidemiology,” “seroprevalence,” or “seroincidence” should be applied to the study in the title or abstract, and the medical subject heading “Seroepidemiologic Studies” be used when the report is of a population-based serological survey Simulation-based research (Cheng et al., 2016) - In abstract or key terms, the MESH or searchable keyword term must have the word simulation or simulated Resources Do you know of any good guidance or resources related to this item? Suggest them via comments below, Twitter, GitHub, or e-mail. References "],
["intro-background-and-rationale-2.html", "Intro: Background and Rationale (2) Explanation Example Field-specific guidance Resources", " Intro: Background and Rationale (2) The items from STROBE state that you should report: - Explain the scientific background and rationale for the investigation being reported The Introduction section should describe why the study was done and what questions and hypotheses it addresses. It should allow others to understand the study’s context and judge its potential contribution to current knowledge. (Vandenbroucke et al., 2007) Some key items to consider adding: - Cite/discuss systematic reviews and meta-analyses - Highlight the gap in research that your work is aiming to fill Explanation The scientific background of the study provides important context for readers. It sets the stage for the study and describes its focus. It gives an overview of what is known on a topic and what gaps in current knowledge are addressed by the study. Background material should note recent pertinent studies and any systematic reviews of pertinent studies.(Vandenbroucke et al., 2007) Example “Concerns about the rising prevalence of obesity in children and adolescents have focused on the well documented associations between childhood obesity and increased cardiovascular risk and mortality in adulthood. Childhood obesity has considerable social and psychological consequences within childhood and adolescence, yet little is known about social, socioeconomic, and psychological consequences in adult life. A recent systematic review found no longitudinal studies on the outcomes of childhood obesity other than physical health outcomes and only two longitudinal studies of the socioeconomic effects of obesity in adolescence. Gortmaker et al. found that US women who had been obese in late adolescence in 1981 were less likely to be married and had lower incomes seven years later than women who had not been overweight, while men who had been overweight were less likely to be married. Sargent et al. found that UK women, but not men, who had been obese at 16 years in 1974 earned 7.4% less than their non-obese peers at age 23. (…) We used longitudinal data from the 1970 British birth cohort to examine the adult socioeconomic, educational, social, and psychological outcomes of childhood obesity” (Vandenbroucke et al., 2007; Viner &amp; Cole, 2005). Field-specific guidance Molecular epidemiology (Gallo et al., 2012) - Explain in the scientiﬁc background of the paper how ⁄why the speciﬁc biomarker(s) have been chosen, potentially among many others (e.g. others are studied but reported elsewhere or not studied at all) Infectious disease molecular epidemiology (Field et al., 2014) - Provide background information about the pathogen population and the distribution of pathogen strains within the host population at risk Seroepidemiologic studies for influenza (Horby et al., 2017) - State what is known about the kinetics of antibody rise, decay, and persistence following infection for the particular virus being studied and the justification for threshold antibody titers or changes in titers used to define evidence of infection - State what is known about the sensitivity and specificity of the antibody detection assay being used Simulation-based research (Cheng et al., 2016) - Clarify whether simulation is subject of research or investigational method for research Resources Do you know of any good guidance or resources related to this item? Suggest them via comments below, Twitter, GitHub, or e-mail. References "],
["intro-objectives-3.html", "Intro: Objectives (3) Explanation Example Field-specific guidance Resources", " Intro: Objectives (3) The item from STROBE states that you should report: - State specific objectives, including any prespecified hypotheses Some key items to consider adding - Mention both primary and secondary pre-specified hypotheses. If the report does not cover all, consider explaining why (covered by another publication, reference protocol, etc.) - If the research is exploratory in nature, state it Explanation Objectives are the detailed aims of the study. Well crafted objectives specify populations, exposures and outcomes, and parameters that will be estimated. They may be formulated as specific hypotheses or as questions that the study was designed to address. In some situations objectives may be less specific, for example, in early discovery phases. Regardless, the report should clearly reflect the investigators’ intentions. For example, if important subgroups or additional analyses were not the original aim of the study but arose during data analysis, they should be described accordingly (see also items 4, 17 and 20). Example “Our primary objectives were to 1) determine the prevalence of domestic violence among female patients presenting to four community-based, primary care, adult medicine practices that serve patients of diverse socioeconomic background and 2) identify demographic and clinical differences between currently abused patients and patients not currently being abused” (McCauley, 1995). Field-specific guidance Molecular epidemiology (Gallo et al., 2012) - A priori hypothesis: if one or more biomarkers are used as proxy measures, state the a priori hypothesis on the expected values of the biomarker(s) Infectious disease molecular epidemiology (Field et al., 2014) - State the epidemiological objectives of using molecular typing Genetic association studies (Little et al., 2009) - State if the study is the first report of a genetic association, a replication effort, or both. Seroepidemiologic studies for influenza (Horby et al., 2017) - State the specific measure of occurrence that is being estimated, for example, point seroprevalence, cumulative incidence of infection, secondary infection risk Veterinary epidemiology [oconnor2016] - Ensure that the level of organization is clear for each objective and hypothesis Resources Do you know of any good guidance or resources related to this item? Suggest them via comments below, Twitter, GitHub, or e-mail. References "],
["methods-study-design-4.html", "Methods: Study Design (4) Box 1. Study designs covered Explanation Example Field-specific guidance Resources", " Methods: Study Design (4) The items from STROBE state that you should report: - Present key elements of study design early in the paper The Methods section should describe what was planned and what was done in sufficient detail to allow others to understand the essential aspects of the study, to judge whether the methods were adequate to provide reliable and valid answers, and to assess whether any deviations from the original plan were reasonable.(Vandenbroucke et al., 2007) Some key items to consider adding: - The reason why the specific sampling method was chosen Box 1. Study designs covered Cohort, case-control, and cross-sectional designs represent different approaches of investigating the occurrence of health-related events in a given population and time period. These studies may address many types of health-related events, including disease or disease remission, disability or complications, death or survival, and the occurrence of risk factors. In cohort studies, the investigators follow people over time. They obtain information about people and their exposures at baseline, let time pass, and then assess the occurrence of outcomes. Investigators commonly make contrasts between individuals who are exposed and not exposed or among groups of individuals with different categories of exposure. Investigators may assess several different outcomes, and examine exposure and outcome variables at multiple points during follow-up. Closed cohorts (for example birth cohorts) enroll a defined number of participants at study onset and follow them from that time forward, often at set intervals up to a fixed end date. In open cohorts the study population is dynamic: people enter and leave the population at different points in time (for example inhabitants of a town). Open cohorts change due to deaths, births, and migration, but the composition of the population with regard to variables such as age and gender may remain approximately constant, especially over a short period of time. In a closed cohort cumulative incidences (risks) and incidence rates can be estimated; when exposed and unexposed groups are compared, this leads to risk ratio or rate ratio estimates. Open cohorts estimate incidence rates and rate ratios. In case-control studies, investigators compare exposures between people with a particular disease outcome (cases) and people without that outcome (controls). Investigators aim to collect cases and controls that are representative of an underlying cohort or a cross-section of a population. That population can be defined geographically, but also more loosely as the catchment area of health care facilities. The case sample may be 100% or a large fraction of available cases, while the control sample usually is only a small fraction of the people who do not have the pertinent outcome. Controls represent the cohort or population of people from which the cases arose. Investigators calculate the ratio of the odds of exposures to putative causes of the disease among cases and controls (see Box 7). Depending on the sampling strategy for cases and controls and the nature of the population studied, the odds ratio obtained in a case-control study is interpreted as the risk ratio, rate ratio or (prevalence) odds ratio (Rodrigues &amp; Kirkwood, 1990; K. Rothman, 1998). The majority of published case-control studies sample open cohorts and so allow direct estimations of rate ratios. In cross-sectional studies, investigators assess all individuals in a sample at the same point in time, often to examine the prevalence of exposures, risk factors or disease. Some cross-sectional studies are analytical and aim to quantify potential causal associations between exposures and disease. Such studies may be analysed like a cohort study by comparing disease prevalence between exposure groups. They may also be analysed like a case-control study by comparing the odds of exposure between groups with and without disease. A difficulty that can occur in any design but is particularly clear in cross-sectional studies is to establish that an exposure preceded the disease, although the time order of exposure and outcome may sometimes be clear. In a study in which the exposure variable is congenital or genetic, for example, we can be confident that the exposure preceded the disease, even if we are measuring both at the same time. (Vandenbroucke et al., 2007) Explanation We advise presenting key elements of study design early in the methods section (or at the end of the introduction) so that readers can understand the basics of the study. For example, authors should indicate that the study was a cohort study, which followed people over a particular time period, and describe the group of persons that comprised the cohort and their exposure status. Similarly, if the investigation used a case-control design, the cases and controls and their source population should be described. If the study was a cross-sectional survey, the population and the point in time at which the cross-section was taken should be mentioned. When a study is a variant of the three main study types, there is an additional need for clarity. For instance, for a casecrossover study, one of the variants of the case-control design, a succinct description of the principles was given in the example above.(McEvoy et al., 2005) We recommend that authors refrain from simply calling a study ‘prospective’ or ‘retrospective’ because these terms are ill defined. (Vandenbroucke et al., 2007) One usage sees cohort and prospective as synonymous and reserves the word retrospective for case-control studies.(Last, 2000) A second usage distinguishes prospective and retrospective cohort studies according to the timing of data collection relative to when the idea for the study was developed.31 A third usage distinguishes prospective and retrospective case-control studies depending on whether the data about the exposure of interest existed when cases were selected.(K. Rothman, 1998) Some advise against using these terms,(MacMahon &amp; Trichopoulos, 1996) or adopting the alternatives ‘concurrent’ and ‘historical’ for describing cohort studies.(Lilienfeld, 1976) In STROBE, we do not use the words prospective and retrospective, nor alternatives such as concurrent and historical. We recommend that, whenever authors use these words, they define what they mean. Most importantly, we recommend that authors describe exactly how and when data collection took place. The first part of the methods section might also be the place to mention whether the report is one of several from a study. If a new report is in line with the original aims of the study, this is usually indicated by referring to an earlier publication and by briefly restating the salient features of the study. However, the aims of a study may also evolve over time. Researchers often use data for purposes for which they were not originally intended, including, for example, official vital statistics that were collected primarily for administrative purposes, items in questionnaires that originally were only included for completeness, or blood samples that were collected for another purpose. For example, the Physicians’ Health Study, a randomized controlled trial of aspirin and carotene, was later used to demonstrate that a point mutation in the factor V gene was associated with an increased risk of venous thrombosis but not of myocardial infarction or stroke.(Ridker et al., 1995) The secondary use of existing data is a creative part of observational research and does not necessarily make results less credible or less important. However, briefly restating the original aims might help readers understand the context of the research and possible limitations in the data.(Vandenbroucke et al., 2007) Example “We used a case-crossover design, a variation of a case-control design that is appropriate when a brief exposure (driver’s phone use) causes a transient rise in the risk of a rare outcome (a crash). We compared a driver’s use of a mobile phone at the estimated time of a crash with the same driver’s use during another suitable time period. Because drivers are their own controls, the design controls for characteristics of the driver that may affect the risk of a crash but do not change over a short period of time. As it is important that risks during control periods and crash trips are similar, we compared phone activity during the hazard interval (time immediately before the crash) with phone activity during control intervals (equivalent times during which participants were driving but did not crash) in the previous week” (McEvoy et al., 2005; Vandenbroucke et al., 2007). Field-specific guidance Molecular epidemiology (Gallo et al., 2012) - Describe the special study designs for molecular epidemiology (in particular, nested case ⁄control and case ⁄cohort) and how they were implemented - Report on the setting of the biological sample collection; amount of sample; nature of collecting procedures; participant conditions; time between sample collection and relevant clinical or physiological endpoints - Report the half-life of the biomarker and chemical and physical characteristics (e.g. solubility) - Describe sample processing (centrifugation, timing, additives, etc.) - Describe sample storage until biomarker analysis (storage, thawing, manipulation, etc.) Infectious disease molecular epidemiology (Field et al., 2014) - Deﬁne or cite deﬁnitions for key molecular terms used within the study (eg, strain, isolate, and clone) - Clearly deﬁne the molecular markers that were used with a standard nomenclature - Clearly state the infectious-disease case deﬁnitions - Describe sample collection and laboratory methods, including any methods used to minimise and measure cross-contamination, and give the criteria used to interpret strain classiﬁcation Seroepidemiologic studies for influenza (Horby et al., 2017) - State which specific seroepidemiologic study design was chosen and why (see Table 1 of Horby et al 2007) Neonatal infections (Fitchett et al., 2016) - Clearly state case ascertainment methods (eg, physician diagnosis, clinical algorithm), documenting individual clinical signs used for diagnosis of possible serious bacterial infection - Give microbiological and/or laboratory and/or radiological criteria for other infectious syndromes (eg, meningitis, sepsis, pneumonia) - Include indications for clinical investigations (eg, lumbar puncture) - Give criteria used to differentiate between new infection episodes and relapses - For facility-based studies, indicate if the study is of community and/ or hospital-acquired infections (HAI), deﬁning HAI using an international standard and presenting speciﬁc HAI clinical syndromes separately - State whether this is an outbreak study, and if so deﬁne an outbreak, with reference to an international standard - Describe sampling strategy (eg, clinical indication vs routine surveillance) and sampling details (eg, minimum volumes; timing in relation to antimicrobial administration - Describe conventional and/or molecular microbiological methods used, with details (eg, automation, enrichment steps), and the use of controls - List pathogens that are likely to be identiﬁed by microbiological methods used - Describe antimicrobial susceptibility tests and thresholds used, with reference to an international standard (eg, CLSI or EUCAST) Resources Do you know of any good guidance or resources related to this item? Suggest them via comments below, Twitter, GitHub, or e-mail. References "],
["methods-setting-5.html", "Methods: Setting (5) Explanation Resources", " Methods: Setting (5) The item from STROBE states that you should report: - Describe the setting, locations, and relevant dates, including periods of recruitment, exposure, follow up, and data collection Some key items to consider adding: - Formative research findings used to inform the study - Describe any characteristics of the study settings that might affect the exposures of the participants, if applicable Explanation Readers need information on setting and locations to assess the context and generalizability of a study’s results. Exposures such as environmental factors and therapies can change over time. Also, study methods may evolve over time. Knowing when a study took place and over what period participants were recruited and followed up places the study in historical context and is important for the interpretation of results. Information about setting includes recruitment sites or sources (eg, electoral roll, outpatient clinic, cancer registry, or tertiary care centre). Information about location may refer to the countries, towns, hospitals or practices where the investigation took place. We advise stating dates rather than only describing the length of time periods. There may be different sets of dates for exposure, disease occurrence, recruitment, beginning and end of follow-up, and data collection. Of note, nearly 80% of 132 reports in oncology journals that used survival analysis included the starting and ending dates for accrual of patients, but only 24% also reported the date on which follow-up ended. (Altman et al., 1995; Vandenbroucke et al., 2007) ## Examples - “The Pasitos Cohort Study recruited pregnant women from Women, Infant and Child clinics in Socorro and San Elizario, El Paso County, Texas and maternal-child clinics of the Mexican Social Security Institute in Ciudad Juarez, Mexico from April 1998 to October 2000. At baseline, prior to the birth of the enrolled cohort children, staff interviewed mothers regarding the household environment. In this ongoing cohort study, we target follow-up exams at 6-month intervals beginning at age 6 months.”(Goodman et al., 2005; Vandenbroucke et al., 2007) ## Field-specific guidance Anti-microbial stewardship programs (Tacconelli et al., 2016) - Describe if setting is epidemic or endemic (high, low, medium) for the study outcome - Specify type of hospital or unit and characteristics of population served by the healthcare setting - Describe antimicrobial formulary in use at the study location related to the analysed antibiotics - Describe infection control measures dedicated to the target resistant bacteria applied at the study location Infectious disease molecular epidemiology (Field et al., 2014) - Clearly state the timeframe of the study; consider and appropriately reference the molecular clock of markers if known, and the natural history of the infection Neonatal infections (Fitchett et al., 2016) - Describe the study context in terms of incidence of neonatal mortality, stillbirth, and preterm birth - Describe the population included (eg, facility births, referrals from home, referrals from another facility) - For community-based studies, describe care-seeking and adherence and time to referral - For facility-based studies, describe obstetric care (basic or comprehensive), including proportion of births by caesarean section. Report annual number of livebirths per facility and state proportion of births in the study area that occur in hospital (vs community) - For facility-based studies, indicate if the facility is public or private, and give the number of health-care staﬀ and their training. Indicate the level of neonatal care available (eg, ventilatory support, indwelling catheters) and investigations available (eg, biochemistry, radiology). Report antimicrobial guidelines used for the empiric management of neonatal sepsis - State the laboratory location and capacity to process diﬀ erent sample types, and give quality control and assurance measures in place Nutritional data (Lachat et al., 2016) - Describe any characteristics of the study settings that might affect the dietary intake or nutritional status of the participants, if applicable Rheumatology (Zavada et al., 2014) - Provide an estimation of drug penetration in source population - Describe eligibility for, and access to, treatment - Outline calendar trends in availability of biologic/ awareness of outcome Seroepidemiologic studies for influenza (Horby et al., 2017) - Describe the timing of the biological sampling in relation to the disease epidemiology in the study population (the beginning, peak, and end of virus transmission) - Where known, describe the timing of biological sampling in individuals in relation to disease onset and to exposures of interest - State the interval between sequential biological samples (serial cross-sectional or longitudinal studies), or specify whether only a single sample was collected (cross-sectional study) Veterinary epidemiology (O’Connor et al., 2016) - If applicable, include information at each level of organization Resources Do you know of any good guidance or resources related to this item? Suggest them via comments below, Twitter, GitHub, or e-mail. References "],
["methods-participants-6.html", "Methods: Participants (6) Explanation 6a Examples 6a Explanation 6b Examples 6b Field-specific guidance Resources", " Methods: Participants (6) The items from STROBE state that you should report: Cohort study - Give the eligibility criteria, and the sources and methods of selection of participants. Describe methods of follow up - For matched studies, give matching criteria and number of exposed and unexposed Case-control study - Give the eligibility criteria, and the sources and methods of case ascertainment and control selection. Give the rationale for the choice of cases and controls - For matched studies, give matching criteria and the number of controls per case Cross-sectional study - Give the eligibility criteria, and the sources and methods of selection of participants Some key items to consider adding: - Define the unit analysed (person, family, twin pairs, department, school, etc.) - Report the source of participants/clinical specimens (e.g., if the participants were a subset from a larger study) - Clearly describe sampling frame and strategy - Report inclusion and exclusion criteria (psychological, dietary/nutritional, physiological, clinical conditions) etc. especially if they might affect key indicators or surrogate endpoints (e.g., biomarkers) - Clear deﬁnitions of exposed and nonexposed cohorts. Justify the choice of comparator - Describe the conditions where subjects may change from one cohort to the other - Describe whether treatment is restricted to new starts or encompasses all individuals with ongoing treatment - Describe incentives for participation and recruitment - Describe follow-up methods and timepoints of assessemnt of serial follow-up - For matched studies, describe matching criteria and the reasons (epidemiological and clinical) for this criteria - For matched studies, detail the number of matched individuals per subject (e.g, number of controls per case) Explanation 6a Detailed descriptions of the study participants help readers understand the applicability of the results. Investigators usually restrict a study population by defining clinical, demographic and other characteristics of eligible participants. Typical eligibility criteria relate to age, gender, diagnosis and comorbid conditions. Despite their importance, eligibility criteria often are not reported adequately. In a survey of observational stroke research, 17 of 49 reports (35%) did not specify eligibility criteria.(Tooth et al., 2005) Eligibility criteria may be presented as inclusion and exclusion criteria, although this distinction is not always necessary or useful. Regardless, we advise authors to report all eligibility criteria and also to describe the group from which the study population was selected (eg, the general population of a region or country), and the method of recruitment (eg, referral or self-selection through advertisements). Knowing details about follow-up procedures, including whether procedures minimized nonresponse and loss to follow-up and whether the procedures were similar for all participants, informs judgments about the validity of results. For example, in a study that used IgM antibodies to detect acute infections, readers needed to know the interval between blood tests for IgM antibodies so that they could judge whether some infections likely were missed because the interval between blood tests was too long. (Metzkor-Cotter et al., 2003) In other studies where follow-up procedures differed between exposed and unexposed groups, readers might recognize substantial bias due to unequal ascertainment of events or differences in nonresponse or loss to follow-up.(Johnson, 1990) Accordingly, we advise that researchers describe the methods used for following participants and whether those methods were the same for all participants, and that they describe the completeness of ascertainment of variables (see also item 14). In case-control studies, the choice of cases and controls is crucial to interpreting the results, and the method of their selection has major implications for study validity. In general controls should reflect the population from which the cases arose. Various methods are used to sample controls, all with advantages and disadvantages: for cases that arise from a general population, population roster sampling, random digit dialling, neighborhood or friend controls are used. Neighborhood or friend controls may present intrinsic matching on exposure.(K. Rothman, 1998) Controls with other diseases may have advantages over population-based controls, in particular for hospital-based cases, because they better reflect the catchment population of a hospital, have greater comparability of recall and ease of recruitment. However, they can present problems if the exposure of interest affects the risk of developing or being hospitalized for the control condition(s). (Berkson, 1946; Feinstein et al., 1986) To remedy this problem often a mixture of the best defensible control diseases is used.(Jick &amp; Vessey, 1978; Vandenbroucke et al., 2007) Examples 6a Cohort Studies “Participants in the Iowa Women’s Health Study were a random sample of all women ages 55 to 69 years derived from the state of Iowa automobile driver’s license list in 1985, which represented approximately 94% of Iowa women in that age group. (. . .) Follow-up questionnaires were mailed in October 1987 and August 1989 to assess vital status and address changes. (. . .) Incident cancers, except for nonmelanoma skin cancers, were ascertained by the State Health Registry of Iowa (. . .). The Iowa Women’s Health Study cohort was matched to the registry with combinations of first, last, and maiden names, zip code, birthdate, and social security number.”(Canto et al., 2000) Case-Control Studies “Cutaneous melanoma cases diagnosed in 1999 and 2000 were ascertained through the Iowa Cancer Registry(. . .). Controls, also identified through the Iowa Cancer Registry, were colorectal cancer patients diagnosed during the same time. Colorectal cancer controls were selected because they are common and have a relatively long survival, and because arsenic exposure has not been conclusively linked to the incidence of colorectal cancer.”(Beane Freeman et al., 2004) Cross-Sectional Studies “We retrospectively identified patients with a principal diagnosis of myocardial infarction (code 410) according to the International Classification of Diseases, 9th Revision, Clinical Modification, from codes designating discharge diagnoses, excluding the codes with a fifth digit of 2, which designates a subsequent episode of care (. . .). A random sample of the entire Medicare cohort with myocardial infarction from February 1994 to July 1995 was selected (. . .). To be eligible, patients had to present to the hospital after at least 30 minutes but less than 12 hours of chest pain and had to have ST-segment elevation of at least 1 mm on two contiguous leads on the initial electrocardiogram.”(Canto et al., 2000) Explanation 6b Matching is much more common in case-control studies, but occasionally, investigators use matching in cohort studies to make groups comparable at the start of follow-up. Matching in cohort studies presents fewer intricacies than with case-control studies. For example, it is not necessary to take the matching into account for the estimation of the relative risk. (Costanza, 1995) Because matching in cohort studies may increase statistical precision investigators might allow for the matching in their analyses and thus obtain narrower confidence intervals. In case-control studies matching is done to increase a study’s efficiency by ensuring similarity in the distribution of variables between cases and controls, in particular the distribution of potential confounding variables. (Costanza, 1995; Stürmer &amp; Brenner, 2002) Because matching can be done in various ways, with one or more controls per case, the rationale for the choice of matching variables and the details of the method used should be described. Commonly used forms of matching are frequency matching (also called group matching) and individual matching. In frequency matching, investigators choose controls so that the distribution of matching variables becomes identical or similar to that of cases. Individual matching involves matching one or several controls to each case. Although intuitively appealing and sometimes useful, matching in case-control studies has a number of disadvantages, is not always appropriate, and needs to be taken into account in the analysis (see box 2). Even apparently simple matching procedures may be poorly reported. For example, authors may state that controls were matched to cases ‘within five years’, or using ‘five year age bands’. Does this mean that, if a case was 54 years old, the respective control needed to be in the five-year age band 50 to 54, or aged 49 to 59, which is within five years of age 54? If a wide (eg, 10-year) age band is chosen, there is a danger of residual confounding by age (see also [box 4][## Box 4. Grouping]), for example because controls may then be younger than cases on average. Examples 6b Cohort Studies “For each patient who initially received a statin, we used propensity-based matching to identify one control who did not receive a statin according to the following protocol. First, propensity scores were calculated for each patient in the entire cohort on the basis of an extensive list of factors potentially related to the use of statins or the risk of sepsis. Second, each statin user was matched to a smaller pool of nonstatin-users by sex, age (plus or minus 1 year), and index date (plus or minus 3 months). Third, we selected the control with the closest propensity score (within 0.2 SD) to each statin user in a 1:1 fashion and discarded the remaining controls.”(Hackam et al., 2006) Case-Control Studies “We aimed to select five controls for every case from among individuals in the study population who had no diagnosis of autism or other pervasive developmental disorders (PDD) recorded in their general practice record and who were alive and registered with a participating practice on the date of the PDD diagnosis in the case. Controls were individually matched to cases by year of birth (up to 1 year older or younger), sex, and general practice. For each of 300 cases, five controls could be identified who met all the matching criteria. For the remaining 994, one or more controls was excluded . . .”(Smeeth et al., 2004) Field-specific guidance Rheumatology (Zavada et al., 2014) - Describe whether treatment reﬂects ﬁrst start until ﬁrst stop of therapy or multiple treatment episodes. If the latter, discuss deﬁnition of duration of exposure and any implications for combining treatment intervals Routinely collected health data (Benchimol et al., 2015) - The methods of study population selection (such as codes or algorithms used to identify subjects) should be listed in detail. If this is not possible, an explanation should be provided - Any validation studies of the codes or algorithms used to select the population should be referenced. If validation was conducted for this study and not published elsewhere, detailed methods and results should be provided - If the study involved linkage of databases, consider use of a ﬂow diagram or other graphical display to demonstrate the data linkage process, including the number of individuals with linked data at each stage Seroepidemiologic studies for influenza (Horby et al., 2017) - For case-ascertained transmission studies, describe the method of case ascertainment and criteria for defining a “case” - For household-or institution-based transmission studies, describe the definition of a household or the institution - For outbreak investigations involving serologic sampling, describe the setting in which the cases were identified, for example, village/residential setting, occupational workplace - To aid the interpretation of seroepidemiologic studies of novel influenza A virus subtypes, the results from exposed populations should be compared with the results from unexposed populations. Efforts to validate the assay in virologically confirmed cases should be reported Neonatal infections (Fitchett et al., 2016) - State age of participants (eg, 0–27 days deﬁ nes neonates; day 0 as day of birth). Disaggregate neonatal data from that of older infants and from stillbirths - Detail the range of gestational age for participants determined a priori to be included in the research, including a lower limit when applicable. - Explain the methods used to determine gestational age (e.g., physical examination, last menstrual period, ultrasonography). If ultrasonography is used, detail the type (vaginal and/or abdominal) and consider describing the criteria used for determination of gestational age. Response-driven sampling (White et al., 2015) - Describe how participants were trained/instructed to recruit others, number of coupons issued per person, any time limits for referral - Describe methods of seed selection and state number at start of study and number added later - State if there was any variation in study procedures during data collection (e.g., changing numbers of coupons per recruiter, interruptions in sampling, or stopping recruitment chains) - Report wording of personal network size question(s) Veterinary epidemiology (O’Connor et al., 2016) - Describe the sources and methods of selection for the owners/managers and for the animals, at each relevant level of organization - Describe the eligibility criteria for the owners/ managers and for the animals, at each relevant level of organization Resources Do you know of any good guidance or resources related to this item? Suggest them via comments below, Twitter, GitHub, or e-mail. References "],
["methods-variables-7.html", "Methods: Variables (7) Explanation Examples Box 2. Matching Field-specific guidance Resources", " Methods: Variables (7) The items from STROBE state that you should report: - Clearly define all outcomes, exposures, predictors, potential confounders, and effect modifiers. Give diagnostic criteria, if applicable. Some key items to consider adding: - The start and stop of any therapies or treatment - The mean, median, and range for each exposure group - The theoretical/conceptual rationale for the design of the intervention/ exposure - The intervention/exposure described with sufficient detail to permit replication - Description of potential confounders (other than epidemiological variables) and correlates - For hypothesis-driven studies, the putative causal structure (consider a diagram like a directed acyclic graph) - Sources of data and methods of assessment for each variable - Comparability of assessment methods among groups and over time - The level of organization at which each variable was measured Explanation Authors should define all variables considered for and included in the analysis, including outcomes, exposures, predictors, potential confounders and potential effect modifiers. Disease outcomes require adequately detailed description of the diagnostic criteria. This applies to criteria for cases in a case-control study, disease events during follow-up in a cohort study and prevalent disease in a cross-sectional study. Clear definitions and steps taken to adhere to them are particularly important for any disease condition of primary interest in the study. For some studies, ‘determinant’ or ‘predictor’ may be appropriate terms for exposure variables and outcomes may be called ‘endpoints’. In multivariable models, authors sometimes use ‘dependent variable’ for an outcome and ‘independent variable’ or ‘explanatory variable’ for exposure and confounding variables. The latter is not precise as it does not distinguish exposures from confounders. If many variables have been measured and included in exploratory analyses in an early discovery phase, consider providing a list with details on each variable in an appendix, additional table or separate publication. Of note, the International Journal of Epidemiology recently launched a new section with ‘cohort profiles’, that includes detailed information on what was measured at different points in time in particular studies. (Ebrahim, 2004; Walker et al., 2004) Finally, we advise that authors declare all ‘candidate variables’ considered for statistical analysis, rather than selectively reporting only those included in the final models (see also item 16a). (Vandenbroucke et al., 2007) Examples “Only major congenital malformations were included in the analyses. Minor anomalies were excluded according to the exclusion list of European Registration of Congenital Anomalies (EUROCAT). If a child had more than one major congenital malformation of one organ system, those malformations were treated as one outcome in the analyses by organ system (…) In the statistical analyses, factors considered potential confounders were maternal age at delivery and number of previous parities. Factors considered potential effect modifiers were maternal age at reimbursement for antiepileptic medication and maternal age at delivery” (Artama et al., 2006; Vandenbroucke et al., 2007) Box 2. Matching In any case-control study, sensible choices need to be made on whether to use matching of controls to cases, and if so, what variables to match on, the precise method of matching to use, and the appropriate method of statistical analysis. Not to match at all may mean that the distribution of some key potential confounders (e.g., age, sex) is radically different between cases and controls. Although this could be adjusted for in the analysis there could be a major loss in statistical efficiency. The use of matching in case-control studies and its interpretation are fraught with difficulties, especially if matching is attempted on several risk factors, some of which may be linked to the exposure of prime interest (K. J. Rothman et al., 1998b; Szklo &amp; Nieto, 2000). For example, in a case-control study of myocardial infarction and oral contraceptives nested in a large pharmaco-epidemiologic data base, with information about thousands of women who are available as potential controls, investigators may be tempted to choose matched controls who had similar levels of risk factors to each case of myocardial infarction. One objective is to adjust for factors that might influence the prescription of oral contraceptives and thus to control for confounding by indication. However, the result will be a control group that is no longer representative of the oral contraceptive use in the source population: controls will be older than the source population because patients with myocardial infarction tend to be older. This has several implications. A crude analysis of the data will produce odds ratios that are usually biased towards unity if the matching factor is associated with the exposure. The solution is to perform a matched or stratified analysis (see item 12d). In addition, because the matched control group ceases to be representative for the population at large, the exposure distribution among the controls can no longer be used to estimate the population attributable fraction (see Box 7) (Cole &amp; MacMahon, 1971). Also, the effect of the matching factor can no longer be studied, and the search for well-matched controls can be cumbersome – making a design with a non-matched control group preferable because the non-matched controls will be easier to obtain and the control group can be larger. Overmatching is another problem, which may reduce the efficiency of matched case-control studies, and, in some situations, introduce bias. Information is lost and the power of the study is reduced if the matching variable is closely associated with the exposure. Then many individuals in the same matched sets will tend to have identical or similar levels of exposures and therefore not contribute relevant information. Matching will introduce irremediable bias if the matching variable is not a confounder but in the causal pathway between exposure and disease. For example, in vitro fertilization is associated with an increased risk of perinatal death, due to an increase in multiple births and low birth weight infants (Gissler &amp; Hemminki, 1996). Matching on plurality or birth weight will bias results towards the null, and this cannot be remedied in the analysis. Matching is intuitively appealing, but the complexities involved have led methodologists to advise against routine matching in case-control studies. They recommend instead a careful and judicious consideration of each potential matching factor, recognizing that it could instead be measured and used as an adjustment variable without matching on it. In response, there has been a reduction in the number of matching factors employed, an increasing use of frequency matching, which avoids some of the problems discussed above, and more case-control studies with no matching at all (Gefeller et al., 1998). Matching remains most desirable, or even necessary, when the distributions of the confounder (e.g., age) might differ radically between the unmatched comparison groups (Costanza, 1995; Stürmer &amp; Brenner, 2002; Vandenbroucke et al., 2007) Field-specific guidance Anti-microbial stewardship programs (Tacconelli et al., 2016) - Specify antimicrobial usage according to: type, dosage, duration and route of administration - Provide information using defined daily dosages (DDDs) and, in addition, other definitions closer to local reality (packages, prescriptions). Provide justification for the measurement presented - Address antimicrobial combinations - Explain rationale for grouping of antimicrobials - Define time at risk for antimicrobial exposure and for resistance development - Provide definition of resistance, multidrug resistance, including pattern of co-resistance; whether studies performed to identify location or resistance eg, plasmid, chromosome, integron, transposon - Definition of infection and/or colonisation. If not a validated reference, provide evidence of robustness of the new definition Genetic association studies (Little et al., 2009) - Clearly define genetic exposures (genetic variants) using a widely-used nomenclature system. Identify variables likely to be associated with population stratification (confounding by ethnic origin) Medical Abortion (Creinin &amp; Chen, 2016) - Exposure: Detail the medications used, including dose(s) and route(s) of administration. If more than one medication is used, state the planned time interval between medications, preferably in hours - Outcome: Define successful medical abortion (should most commonly be considered as successful expulsion of the intrauterine pregnancy without need for surgical intervention) - Outcome: Define the types of medical abortion failure (e.g., ongoing pregnancy, incomplete abortion, participant symptoms). Continuing pregnancy should be defined as a viable pregnancy following treatment (to be differentiated from a non-viable [i.e., retained gestational sac] Neonatal infections (Fitchett et al., 2016) - State criteria used to deﬁne clinically signiﬁcant organisms for each sample type Nutritional data (Lachat et al., 2016) - Clearly deﬁne foods, food groups, nutrients, or other food components - When using dietary patterns or indices, describe the methods to obtain them and their nutritional properties Seroepidemiologic studies for influenza (Horby et al., 2017) - Describe illness definitions and methods for ascertaining the presence or absence of clinical illness in subjects - Describe the potential for immunization (specify vaccine and timing of vaccination in relationship to collection of serum), if applicable, to affect the outcome measures - Describe any known or potential immunological cross-reactivity that may bias the outcome measures Response-driven sampling (White et al., 2015) - State how recruiter–recruit relationship was tracked Routinely collected health data (Benchimol et al., 2015) - A complete list of codes and algorithms used to classify exposures, outcomes, confounders, and effect modiﬁers should be provided. If these cannot be reported, an explanation should be provided Seroepidemiologic studies for influenza (Horby et al., 2017) - Describe any known or potential immunological cross* reactivity that may bias the outcome measures Resources Do you know of any good guidance or resources related to this item? Suggest them via comments below, Twitter, GitHub, or e-mail. Shrier, I., &amp; Platt, R. W. (2008). Reducing bias through directed acyclic graphs. BMC Medical Research Methodology, 8(1), 70. https://doi.org/10.1186/1471-2288-8-70 (Shrier &amp; Platt, 2008) Students 4 Best Evidence. (2018). A beginner’s guide to confounding. In Students 4 Best Evidence. https://www.students4bestevidence.net/blog/2018/10/01/a-beginners-guide-to-confounding/ (Students 4 Best Evidence, 2018) VanderWeele, T. J. (2019). Principles of confounder selection. European Journal of Epidemiology, 34(3), 211–219. https://doi.org/10.1007/s10654-019-00494-6 (VanderWeele, 2019) References "],
["methods-datameasurement-8.html", "Methods: Data/Measurement (8) Explanation Examples Field-specific guidance Resources", " Methods: Data/Measurement (8) The items from STROBE state that you should report: - For each variable of interest, give sources of data and details of methods of assessment (measurement). Describe comparability of assessment methods if there is more than one group. Some key items to consider adding: - The validity/reliability of the assessment methods (survey development, validation, and evaluation) - Timing, timepoints, and length of followup - Any blinding of participants or data collectors - Any methods used to support data integrity or the accuracy of the data (e.g., double-entry, methods for “data cleaning”) - Any methods used to enhance the quality of measurements - Comparability of assessment methods among groups and over time Explanation The way in which exposures, confounders and outcomes were measured affects the reliability and validity of a study. Measurement error and misclassification of exposures or outcomes can make it more difficult to detect cause-effect relationships, or may produce spurious relationships. Error in measurement of potential confounders can increase the risk of residual confounding. (Becher, 1992; Brenner &amp; Blettner, 1997). It is helpful, therefore, if authors report the findings of any studies of the validity or reliability of assessments or measurements, including details of the reference standard that was used. Rather than simply citing validation studies (as in the first example), we advise that authors give the estimated validity or reliability, which can then be used for measurement error adjustment or sensitivity analyses (see items [12e][Explanation-12e] and [17][Results:-Other-Analyses-(17)]). In addition, it is important to know if groups being compared differed with respect to the way in which the data were collected. This may be important for laboratory examinations (as in the second example) and other situations. For instance, if an interviewer first questions all the cases and then the controls, or vice versa, bias is possible because of the learning curve; solutions such as randomizing the order of interviewing may avoid this problem. Information bias may also arise if the compared groups are not given the same diagnostic tests or if one group receives more tests of the same kind than another (see also item 9). Examples Example 1. “Total caffeine intake was calculated primarily using US Department of Agriculture food composition sources. In these calculations, it was assumed that the content of caffeine was 137 mg per cup of coffee, 47 mg per cup of tea, 46 mg per can or bottle of cola beverage, and 7 mg per serving of chocolate candy. This method of measuring (caffeine) intake was shown to be valid in both the NHS I cohort and a similar cohort study of male health professionals (…) Self-reported diagnosis of hypertension was found to be reliable in the NHS I cohort” (Vandenbroucke et al., 2007; Winkelmayer et al., 2005). Example 2. “Samples pertaining to matched cases and controls were always analyzed together in the same batch and laboratory personnel were unable to distinguish among cases and controls” (Lukanova et al., 2006; Vandenbroucke et al., 2007). Field-specific guidance Anti-microbial stewardship programs (Tacconelli et al., 2016) - Describe how antimicrobial consumption data were obtained (pharmacy, patients’ charts, etc) and if it was actually used or purchased/ dispensed Molecular epidemiology (Gallo et al., 2012) - Laboratory methods: report type of assay used, detection limit, quantity of biological sample used, outliers, timing in the assay procedures (when applicable) and calibration procedures or any standard used Genetic association studies (Little et al., 2009) - Describe laboratory methods, including source and storage of DNA, genotyping methods and platforms (including the allele calling algorithm used, and its version), error rates and call rates - State the laboratory/centre where genotyping was done - Describe comparability of laboratory methods if there is more than one group - Specify whether genotypes were assigned using all of the data from the study simultaneously or in smaller batches Infectious disease molecular epidemiology (Field et al., 2014) - Describe any methods used to detect multiple-strain infections and measure their eﬀect on the study ﬁndings Nutritional data (Lachat et al., 2016) - Describe the dietary assessment method(s), e.g., portion size estimation, number of days and items recorded, how it was developed and administered, and how quality was assured. Report if and how supplement intake was assessed - Describe and justify food composition data used. Explain the procedure to match food composition with consumption data. Describe the use of conversion factors, if applicable. - Describe the nutrient requirements, recommendations, or dietary guidelines and the evaluation approach used to compare intake with the dietary reference values, if applicable. - When using nutritional biomarkers, additionally use the STROBE Extension for Molecular Epidemiology (STROBE-ME). Report the type of biomarkers used and their usefulness as dietary exposure markers - Describe the assessment of nondietary data (e.g., nutritional status and inﬂuencing factors) and timing of the assessment of these variables in relation to dietary assessment Seroepidemiologic studies for influenza (Horby et al., 2017) - If relevant, describe measures taken to identify and record immunization history Response-driven sampling (White et al., 2015) - Describe methods to assess eligibility and reduce repeat enrollment (e.g., coupon manager software, biometrics) Resources Do you know of any good guidance or resources related to this item? Suggest them via comments below, Twitter, GitHub, or e-mail. References "],
["methods-bias-9.html", "Methods: Bias (9) Explanation Examples Box 3. Bias Field-specific guidance Resources", " Methods: Bias (9) The items from STROBE state that you should report: - Describe any efforts to address potential sources of bias Some key items to consider adding: - Describe the nature and magnitude of any potential biases and explain what approach was used to deal with these (e.g., discovery, ascertainment, selection, information, etc.) - For quantitative outcome variables, specify if any investigation of potential bias resulting from pharmacotherapy was undertaken - Report how bias in dietary or nutritional assessment was addressed, e.g., misreporting, changes in habits as a result of being measured, or data imputation from other sources Explanation Biased studies produce results that differ systematically from the truth (see also box 3). It is important for a reader to know what measures were taken during the conduct of a study to reduce the potential of bias. Ideally, investigators carefully consider potential sources of bias when they plan their study. At the stage of reporting, we recommend that authors always assess the likelihood of relevant biases. Specifically, the direction and magnitude of bias should be discussed and, if possible, estimated. For instance, in casecontrol studies information bias can occur, but may be reduced by selecting an appropriate control group, as in the first example.(Phillips et al., 2002) Differences in the medical surveillance of participants were a problem in the second example.(Pasquale et al., 2006) Consequently, the authors provide more detail about the additional data they collected to tackle this problem. When investigators have set up quality control programs for data collection to counter a possible “drift” in measurements of variables in longitudinal studies, or to keep variability at a minimum when multiple observers are used, these should be described. Unfortunately, authors often do not address important biases when reporting their results. Among 43 case-control and cohort studies published from 1990 to 1994 that investigated the risk of second cancers in patients with a history of cancer, medical surveillance bias was mentioned in only 5 articles.(Craig &amp; Feinstein, 1999) A survey of reports of mental health research published during 1998 in 3 psychiatric journals found that only 13% of 392 articles mentioned response bias.(Rogler et al., 2001) A survey of cohort studies in stroke research found that 14 of 49 (28%) articles published from 1999 to 2003 addressed potential selection bias in the recruitment of study participants and 35 (71%) mentioned the possibility that any type of bias may have affected results.5 (Vandenbroucke et al., 2007) Examples Example 1. “In most case-control studies of suicide, the control group comprises living individuals but we decided to have a control group of people who had died of other causes (…). With a control group of deceased individuals, the sources of information used to assess risk factors are informants who have recently experienced the death of a family member or close associate - and are therefore more comparable to the sources of information in the suicide group than if living controls were used” (Phillips et al., 2002). Example 2. “Detection bias could influence the association between Type 2 diabetes mellitus (T2DM) and primary open-angle glaucoma (POAG) if women with T2DM were under closer ophthalmic surveillance than women without this condition. We compared the mean number of eye examinations reported by women with and without diabetes. We also recalculated the relative risk for POAG with additional control for covariates associated with more careful ocular surveillance (a self-report of cataract, macular degeneration, number of eye examinations, and number of physical examinations).” (Pasquale et al., 2006; Vandenbroucke et al., 2007) Box 3. Bias Bias is a systematic deviation of a study’s result from a true value. Typically, it is introduced during the design or implementation of a study and cannot be remedied later. Bias and confounding are not synonymous. Bias arises from flawed information or subject selection so that a wrong association is found. Confounding produces relations that are factually right, but that cannot be interpreted causally because some underlying, unaccounted for factor is associated with both exposure and outcome (see Box 5). Also, bias needs to be distinguished from random error, a deviation from a true value caused by statistical fluctuations (in either direction) in the measured data. Many possible sources of bias have been described and a variety of terms are used (Murphy, 1976; Sackett, 1979). We find two simple categories helpful: information bias and selection bias. Information bias occurs when systematic differences in the completeness or the accuracy of data lead to differential misclassification of individuals regarding exposures or outcomes. For instance, if diabetic women receive more regular and thorough eye examinations, the ascertainment of glaucoma will be more complete than in women without diabetes (see item 9) (Pasquale et al., 2006). Patients receiving a drug that causes non-specific stomach discomfort may undergo gastroscopy more often and have more ulcers detected than patients not receiving the drug – even if the drug does not cause more ulcers. This type of information bias is also called ‘detection bias’ or ‘medical surveillance bias’. One way to assess its influence is to measure the intensity of medical surveillance in the different study groups, and to adjust for it in statistical analyses. In case-control studies information bias occurs if cases recall past exposures more or less accurately than controls without that disease, or if they are more or less willing to report them (also called ‘recall bias’). ‘Interviewer bias’ can occur if interviewers are aware of the study hypothesis and subconsciously or consciously gather data selectively (Johannes et al., 1997). Some form of blinding of study participants and researchers is therefore often valuable. Selection bias may be introduced in case-control studies if the probability of including cases or controls is associated with exposure. For instance, a doctor recruiting participants for a study on deep-vein thrombosis might diagnose this disease in a woman who has leg complaints and takes oral contraceptives. But she might not diagnose deep-vein thrombosis in a woman with similar complaints who is not taking such medication. Such bias may be countered by using cases and controls that were referred in the same way to the diagnostic service (Bloemenkamp et al., 1999). Similarly, the use of disease registers may introduce selection bias: if a possible relationship between an exposure and a disease is known, cases may be more likely to be submitted to a register if they have been exposed to the suspected causative agent (Feinstein, 1985). ‘Response bias’ is another type of selection bias that occurs if differences in characteristics between those who respond and those who decline participation in a study affect estimates of prevalence, incidence and, in some circumstances, associations. In general, selection bias affects the internal validity of a study. This is different from problems that may arise with the selection of participants for a study in general, which affects the external rather than the internal validity of a study (also see item 21).(Vandenbroucke et al., 2007) Field-specific guidance Seroepidemiologic studies for influenza (Horby et al., 2017) - If relevant, describe efforts to control for the potential effect of immunization on estimates of outcomes Resources Do you know of any good guidance or resources related to this item? Suggest them via comments below, Twitter, GitHub, or e-mail. -Boffetta, P. (1995). Sources of bias, effect of confounding in the application of biomarkers to epidemiological studies. Toxicology Letters, 77(1), 235–238. https://doi.org/10.1016/0378-4274(95)03301-7 (Boffetta, 1995) - Centre for Evidence-Based Medicine. (2017). Catalogue of Bias. In Catalog of Bias. https://catalogofbias.org/ (Centre for Evidence-Based Medicine, 2017) References "],
["methods-study-size-10.html", "Methods: Study Size (10) Examples Explanation Box 4. Grouping Field-specific guidance", " Methods: Study Size (10) The items from STROBE state that you should report: - Explain how the study size was arrived at The sample size needed for a study depends on many factors including the size of the model, distribution of the variables, amount of missing data, reliability of the variables, and strength of the relationships among the variables. Some key items to consider adding: - Any unique restrictions placed on the study sample size - Different determinants of sample size for different levels of organization (e.g., parent and offspring, family unit, etc.) - How non-independence of measurements was incorporated into sample-size considerations - The parameters, assumptions, methods, and effect size justification of the sample size calculation Examples Example 1. “The number of cases in the area during the study period determined the sample size” (Vandenbroucke et al., 2007; Yadon et al., 2003). Example 2. “A survey of postnatal depression in the region had documented a prevalence of 19.8%. Assuming depression in mothers with normal weight children to be 20% and an odds ratio of 3 for depression in mothers with a malnourished child we needed 72 case-control sets (one case to one control) with an 80% power and 5% significance” (Anoop et al., 2004; Vandenbroucke et al., 2007). Explanation A study should be large enough to obtain a point estimate with a sufficiently narrow confidence interval to meaningfully answer a research question. Large samples are needed to distinguish a small association from no association. Small studies often provide valuable information, but wide confidence intervals may indicate that they contribute less to current knowledge in comparison with studies providing estimates with narrower confidence intervals. Also, small studies that show ‘interesting’ or ‘statistically significant’ associations are published more frequently than small studies that do not have ‘significant’ findings. While these studies may provide an early signal in the context of discovery, readers should be informed of their potential weaknesses. The importance of sample size determination in observational studies depends on the context. If an analysis is performed on data that were already available for other purposes, the main question is whether the analysis of the data will produce results with sufficient statistical precision to contribute substantially to the literature, and sample size considerations will be informal. Formal, a priori calculation of sample size may be useful when planning a new study (Carlin &amp; Doyle, 2002; Rigby &amp; Vail, 1998). Such calculations are associated with more uncertainty than implied by the single number that is generally produced. For example, estimates of the rate of the event of interest or other assumptions central to calculations are commonly imprecise, if not guesswork (KF &amp; DA, n.d.). The precision obtained in the final analysis can often not be determined beforehand because it will be reduced by inclusion of confounding variables in multivariable analyses (Drescher et al., 1990), the degree of precision with which key variables can be measured (Devine &amp; Smith, 1998), and the exclusion of some individuals. Few epidemiological studies explain or report deliberations about sample size.(Pocock et al., 2004; Tooth et al., 2005) We encourage investigators to report pertinent formal sample size calculations if they were done. In other situations they should indicate the considerations that determined the study size (eg, a fixed available sample, as in the first example above). If the observational study was stopped early when statistical significance was achieved, readers should be told. Do not bother readers with post hoc justifications for study size or retrospective power calculations.(KF &amp; DA, n.d.) From the point of view of the reader, confidence intervals indicate the statistical precision that was ultimately obtained. It should be realized that confidence intervals reflect statistical uncertainty only, and not all uncertainty that may be present in a study (see item 20).(Vandenbroucke et al., 2007) Box 4. Grouping There are several reasons why continuous data may be grouped (Altman, n.d.). When collecting data it may be better to use an ordinal variable than to seek an artificially precise continuous measure for an exposure based on recall over several years. Categories may also be helpful for presentation, for example to present all variables in a similar style, or to show a dose-response relationship. Grouping may also be done to simplify the analysis, for example to avoid an assumption of linearity. However, grouping loses information and may reduce statistical power (Cohen, 1983) especially when dichotomization is used (R. C. MacCallum et al., 2002; Royston et al., 2006; Zhao &amp; Kolonel, 1992). If a continuous confounder is grouped, residual confounding may occur, whereby some of the variable’s confounding effect remains unadjusted for (see Box 5) (Becher, 1992; Cochran, 1968). Increasing the number of categories can diminish power loss and residual confounding, and is especially appropriate in large studies. Small studies may use few groups because of limited numbers. Investigators may choose cut-points for groupings based on commonly used values that are relevant for diagnosis or prognosis, for practicality, or on statistical grounds. They may choose equal numbers of individuals in each group using quantiles (Clayton &amp; Hills, 1993). On the other hand, one may gain more insight into the association with the outcome by choosing more extreme outer groups and having the middle group(s) larger than the outer groups (Cox, 1957). In case-control studies, deriving a distribution from the control group is preferred since it is intended to reflect the source population. Readers should be informed if cut-points are selected post hoc from several alternatives. In particular, if the cut-points were chosen to minimise a P value the true strength of an association will be exaggerated (Altman, 1994). When analysing grouped variables, it is important to recognise their underlying continuous nature. For instance, a possible trend in risk across ordered groups can be investigated. A common approach is to model the rank of the groups as a continuous variable. Such linearity across group scores will approximate an actual linear relation if groups are equally spaced (e.g., 10 year age groups) but not otherwise. Il’yasova et al (Il’yasova et al., 2005) recommend publication of both the categorical and the continuous estimates of effect, with their standard errors, in order to facilitate meta-analysis, as well as providing intrinsically valuable information on dose-response. One analysis may inform the other and neither is assumption-free. Authors often ignore the ordering and consider the estimates (and P values) separately for each category compared to the reference category. This may be useful for description, but may fail to detect a real trend in risk across groups. If a trend is observed, a confidence interval for a slope might indicate the strength of the observation. Field-specific guidance Seroepidemiologic studies for influenza (Horby et al., 2017) - Describe the baseline estimated seroprevalence at given antibody titers or incidence of infection and cite published literature to support these estimates ## Resources Do you know of any good guidance or resources related to this item? Suggest them via comments below, Twitter, GitHub, or e-mail. Coppock, A. Power Calculator (Shiny App). Retrieved January 27, 2020, from https://egap.shinyapps.io/Power_Calculator/ (Coppock, n.d.) References "],
["methods-quantitative-variables-11.html", "Methods: Quantitative variables (11) Explanation Example Field-specific guidance Resources", " Methods: Quantitative variables (11) The items from STROBE state that you should report: - Explain how quantitative variables were handled in the analyses. If applicable, describe which groupings were chosen, and why Some key items to consider adding: - If applicable, describe how effects of treatment were dealt with Explanation Investigators make choices regarding how to collect and analyse quantitative data about exposures, effect modifiers and confounders. For example, they may group a continuous exposure variable to create a new categorical variable (see box 4). Grouping choices may have important consequences for later analyses (Altman, 1994; Royston et al., 2006). We advise that authors explain why and how they grouped quantitative data, including the number of categories, the cut-points, and category mean or median values. Whenever data are reported in tabular form, the counts of cases, controls, persons at risk, person-time at risk, etc. should be given for each category. Tables should not consist solely of effect-measure estimates or results of model fitting. Investigators might model an exposure as continuous in order to retain all the information. In making this choice, one needs to consider the nature of the relationship of the exposure to the outcome. As it may be wrong to assume a linear relation automatically, possible departures from linearity should be investigated. Authors could mention alternative models they explored during analyses (eg, using log transformation, quadratic terms or spline functions). Several methods exist for fitting a nonlinear relation between the exposure and outcome (Greenland, 1995; Royston et al., 1999, 2006). Also, it may be informative to present both continuous and grouped analyses for a quantitative exposure of prime interest. In a recent survey, two thirds of epidemiological publications studied quantitative exposure variables (Pocock et al., 2004). In 42 of 50 articles (84%) exposures were grouped into several ordered categories, but often without any stated rationale for the choices made. Fifteen articles used linear associations to model continuous exposure but only 2 reported checking for linearity. In another survey, of the psychological literature, dichotomization was justified in only 22 of 110 articles (20%) (R. MacCallum et al., 2002). Example “Patients with a Glasgow Coma Scale less than 8 are considered to be seriously injured. A GCS of 9 or more indicates less serious brain injury. We examined the association of GCS in these two categories with the occurrence of death within 12 months from injury” (Linn et al., 2007). Field-specific guidance Anti-microbial stewardship programs (Tacconelli et al., 2016) - Provide subgroup analyses for immunocompromised, surgical/medical patients and patients in intensive care units, if applicable Nutritional data (Lachat et al., 2016) - Explain the categorization of dietary/nutritional data (e.g., use of N-tiles and handling of nonconsumers) and the choice of reference category, if applicable Seroepidemiologic studies for influenza (Horby et al., 2017) - Describe the serological assay’s limit of detection and how this limit is defined or calculated. Describe how samples with a result below or on the borderline of the limit were handled in the analysis - Describe and justify the titer or other result used to define “seropositivity,” or the antibody titer change or change in other assay result used to define “seroconversion.” Avoid the term “seroconversion” unless referring to change from undetectable to detectable antibody level. Otherwise report the fold-rise in titer. Avoid the term “infection” but report “seroprevalence at a titer of ….” - If statements or inferences are made about protection from infection, describe what is known about the correlation between the assay results and protection from infection and illness Resources Do you know of any good guidance or resources related to this item? Suggest them via comments below, Twitter, GitHub, or e-mail. References "],
["methods-statistical-methods-12.html", "Methods: Statistical Methods (12) Explanation 12a Examples 12a Explanation 12b Examples 12b Box 5. Confounding Explanation 12c Examples 12c Explanation 12d Cohort Box 6. Missing data Explanation 12d Case-Control Explanation 12d Cross-sectional Explanation 12e Field-specific guidance Resources Do you know of any good guidance or resources related to this item? Suggest them via comments below, Twitter, GitHub, or e-mail.", " Methods: Statistical Methods (12) The items from STROBE state that you should report: - Describe all statistical methods, including those used to control for confounding (12a) - Describe any methods used to examine subgroups and interactions (12b) - Explain how missing data were addressed (12c) - Cohort study If applicable, explain how loss to follow up was addressed (12d) - Case-control study If applicable, explain how matching of cases and controls was addressed (12d) - Cross-sectional study If applicable, describe analytical methods taking account of sampling strategy (12d) - Describe any sensitivity analyses (12e) Some key items to consider adding: - All statistical methods for each objective at a level of detail sufficient for a knowledgeable reader to replicate the methods - Clearly indicate the unit of analysis (e.g., individual, team, family, unit, etc.) - The validity and reliability of any measurements used - If any internal/external validation was done - How items/variables were selected/introduced into statistical models - Data analysis software version and options/settings used - If the same association under study has previously been published, consider using a similar analysis model and deﬁnitions for replicative purposes - Methods used to – Assess robustness of analyses (e.g, sensitivity analyses, quantitative bias assessment) – Adjust for measurement error, (i.e., from a validity or calibration study) – Account for (complex) sampling strategy (e.g., estimator used) – Address missing data or loss-to-follow-up – Control for confounding – Manage and correct for for non-independence (i.e., relatedness) of data – Address multiple comparisons or to control for the risk of false positive findings – Assess and address population stratification – Identify and address repeated measures on subjects – Clean data – Match, combine, or link data (person/individual/dataset level linkages) and an evaluation of the linkage quality Explanation 12a In general, there is no one correct statistical analysis but, rather, several possibilities that may address the same question, but make different assumptions. Regardless, investigators should pre-determine analyses at least for the primary study objectives in a study protocol. Often additional analyses are needed, either instead of, or as well as, those originally envisaged, and these may sometimes be motivated by the data. When a study is reported, authors should tell readers whether particular analyses were suggested by data inspection. Even though the distinction between pre-specified and exploratory analyses may sometimes be blurred, authors should clarify reasons for particular analyses. If groups being compared are not similar with regard to some characteristics, adjustment should be made for possible confounding variables by stratification or by multivariable regression (see box 5). (Slama &amp; Werwatz, 2005) Often, the study design determines which type of regression analysis is chosen. For instance, Cox proportional hazard regression is commonly used in cohort studies, (S, n.d.-b) whereas logistic regression is often the method of choice in case-control studies. (Schlesselman, 1982; WD, 1994). Analysts should fully describe specific procedures for variable selection and not only present results from the final model. (Altman et al., 1983; Clayton &amp; Hills, 1993) If model comparisons are made to narrow down a list of potential confounders for inclusion in a final model, this process should be described. It is helpful to tell readers if one or two covariates are responsible for a great deal of the apparent confounding in a data analysis. Other statistical analyses such as imputation procedures, data transformation, and calculations of attributable risks should also be described. Nonstandard or novel approaches should be referenced and the statistical software used reported. As a guiding principle, we advise statistical methods be described “with enough detail to enable a knowledgeable reader with access to the original data to verify the reported results.” (International Committee of Medical Journal Editors, 1997) In an empirical study, only 93 of 169 articles (55%) reporting adjustment for confounding clearly stated how continuous and multi-category variables were entered into the statistical model. (Müllner et al., 2002) Another study found that among 67 articles in which statistical analyses were adjusted for confounders, it was mostly unclear how confounders were chosen. (Pocock et al., 2004) Examples 12a “The adjusted relative risk was calculated using the Mantel-Haenszel technique, when evaluating if confounding by age or gender was present in the groups compared. The 95% confidence interval (CI) was computed around the adjusted relative risk, using the variance according to Greenland and Robins and Robins et al.” (Berglund et al., 2001; Vandenbroucke et al., 2007). Explanation 12b As discussed in detail under item 17, many debate the use and value of analyses restricted to subgroups of the study population. (Gotzsche, 2006; Pocock et al., 2004) Subgroup analyses are nevertheless often done. (Pocock et al., 2004) Readers need to know which subgroup analyses were planned in advance, and which arose while analyzing the data. Also, it is important to explain what methods were used to examine whether effects or associations differed across groups (see item 17). Interaction relates to the situation when one factor modifies the effect of another (therefore also called ‘effect modification’). The joint action of two factors can be characterized in two ways: on an additive scale, in terms of risk differences; or on a multiplicative scale, in terms of relative risk (see box 8). Many authors and readers may have their own preference about the way interactions should be analyzed. Still, they may be interested to know to what extent the joint effect of exposures differs from the separate effects. There is consensus that the additive scale, which uses absolute risks, is more appropriate for public health and clinical decision making. (Szklo &amp; Nieto, 2000) Whatever view is taken, this should be clearly presented to the reader, as is done in the example above. (Hallan et al., 2006) A lay-out presenting separate effects of both exposures as well as their joint effect, each relative to no exposure, might be most informative. It is presented in the example for interaction under item 17, and the calculations on the different scales are explained in box 8. Examples 12b “Sex differences in susceptibility to the 3 lifestyle-related risk factors studied were explored by testing for biological interaction according to Rothman: a new composite variable with 4 categories (a−b−, a−b+, a+b−, and a+b+) was redefined for sex and a dichotomous exposure of interest where a− and b− denote absence of exposure. RR was calculated for each category after adjustment for age. An interaction effect is defined as departure from additivity of absolute effects, and excess RR caused by interaction (RERI) was calculated: - where RR(a+b+) denotes RR among those exposed to both factors where RR(a−b−) is used as reference category (RR = 1.0). Ninety-five percent CIs were calculated as proposed by Hosmer and Lemeshow. RERI of 0 means no interaction” (Hallan et al., 2006; Vandenbroucke et al., 2007). Box 5. Confounding Confounding literally means confusion of effects. A study might seem to show either an association or no association between an exposure and the risk of a disease. In reality, the seeming association or lack of association is due to another factor that determines the occurrence of the disease but that is also associated with the exposure. The other factor is called the confounding factor or confounder. Confounding thus gives a wrong assessment of the potential ‘causal’ association of an exposure. For example, if women who approach middle age and develop elevated blood pressure are less often prescribed oral contraceptives, a simple comparison of the frequency of cardiovascular disease between those who use contraceptives and those who do not, might give the wrong impression that contraceptives protect against heart disease. Investigators should think beforehand about potential confounding factors. This will inform the study design and allow proper data collection by identifying the confounders for which detailed information should be sought. Restriction or matching may be used. In the example above, the study might be restricted to women who do not have the confounder, elevated blood pressure. Matching on blood pressure might also be possible, though not necessarily desirable (see Box 2). In the analysis phase, investigators may use stratification or multivariable analysis to reduce the effect of confounders. Stratification consists of dividing the data in strata for the confounder (e.g., strata of blood pressure), assessing estimates of association within each stratum, and calculating the combined estimate of association as a weighted average over all strata. Multivariable analysis achieves the same result but permits one to take more variables into account simultaneously. It is more flexible but may involve additional assumptions about the mathematical form of the relationship between exposure and disease. Taking confounders into account is crucial in observational studies, but readers should not assume that analyses adjusted for confounders establish the ‘causal part’ of an association. Results may still be distorted by residual confounding (the confounding that remains after unsuccessful attempts to control for it (Olsen &amp; Basso, 1999), random sampling error, selection bias and information bias (see Box 3). Explanation 12c Missing data are common in observational research. Questionnaires posted to study participants are not always filled in completely, participants may not attend all follow-up visits and routine data sources and clinical databases are often incomplete. Despite its ubiquity and importance, few papers report in detail on the problem of missing data. (Tooth et al., 2005; Vach &amp; Blettner, 1991) Investigators may use any of several approaches to address missing data. We describe some strengths and limitations of various approaches in box 6. We advise that authors report the number of missing values for each variable of interest (exposures, outcomes, confounders) and for each step in the analysis. Authors should give reasons for missing values if possible, and indicate how many individuals were excluded because of missing data when describing the flow of participants through the study (see also item 13). For analyses that account for missing data, authors should describe the nature of the analysis (eg, multiple imputation) and the assumptions that were made (eg, missing at random, see box 6). (Vandenbroucke et al., 2007) Examples 12c “Our missing data analysis procedures used missing at random (MAR) assumptions. We used the MICE (multivariate imputation by chained equations) method of multiple multivariate imputation in STATA. We independently analysed 10 copies of the data, each with missing values suitably imputed, in the multivariate logistic regression analyses. We averaged estimates of the variables to give a single mean estimate and adjusted standard errors according to Rubin’s rules” (Chandola et al., 2006; Vandenbroucke et al., 2007). Explanation 12d Cohort Cohort studies are analyzed using life table methods or other approaches that are based on the person-time of follow- up and time to developing the disease of interest. Among individuals who remain free of the disease at the end of their observation period, the amount of follow-up time is assumed to be unrelated to the probability of developing the outcome. This will be the case if follow-up ends on a fixed date or at a particular age. Loss to follow-up occurs when participants withdraw from a study before that date. This may hamper the validity of a study if loss to follow-up occurs selectively in exposed individuals, or in persons at high risk of developing the disease (‘informative censoring’). In the example above, patients lost to follow-up in treatment programs with no active follow-up had fewer CD4 helper cells than those remaining under observation and were therefore at higher risk of dying. (Braitstein et al., 2006) It is important to distinguish persons who reach the end of the study from those lost to follow-up. Unfortunately, statistical software usually does not distinguish between the two situations: in both cases follow-up time is automatically truncated (‘censored’) at the end of the observation period. Investigators therefore need to decide, ideally at the stage of planning the study, how they will deal with loss to follow-up. When few patients are lost, investigators may either exclude individuals with incomplete follow-up, or treat them as if they withdrew alive at either the date of loss to follow-up or the end of the study. We advise authors to report how many patients were lost to follow-up and what censoring strategies they used. Box 6. Missing data Problems and possible solutions A common approach to dealing with missing data is to restrict analyses to individuals with complete data on all variables required for a particular analysis. Although such ‘complete-case’ analyses are unbiased in many circumstances, they can be biased and are always inefficient (Little &amp; Rubin, 2002). Bias arises if individuals with missing data are not typical of the whole sample. Inefficiency arises because of the reduced sample size for analysis. Using the last observation carried forward for repeated measures can distort trends over time if persons who experience a foreshadowing of the outcome selectively drop out (Ware, 2009). Inserting a missing category indicator for a confounder may increase residual confounding (Vach &amp; Blettner, 1991). Imputation, in which each missing value is replaced with an assumed or estimated value, may lead to attenuation or exaggeration of the association of interest, and without the use of sophisticated methods described below may produce standard errors that are too small. Rubin developed a typology of missing data problems, based on a model for the probability of an observation being missing (Little &amp; Rubin, 2002; Rubin, 1976). Data are described as missing completely at random (MCAR) if the probability that a particular observation is missing does not depend on the value of any observable variable(s). Data are missing at random (MAR) if, given the observed data, the probability that observations are missing is independent of the actual values of the missing data. For example, suppose younger children are more prone to missing spirometry measurements, but that the probability of missing is unrelated to the true unobserved lung function, after accounting for age. Then the missing lung function measurement would be MAR in models including age. Data are missing not at random (MNAR) if the probability of missing still depends on the missing value even after taking the available data into account. When data are MNAR valid inferences require explicit assumptions about the mechanisms that led to missing data. Methods to deal with data missing at random (MAR) fall into three broad classes (Little &amp; Rubin, 2002; Schafer, 1997): likelihood-based approaches (Lipsitz et al., 1999), weighted estimation (Rotnitzky &amp; Robins, 1997) and multiple imputation (DB, 1987; Little &amp; Rubin, 2002). Of these three approaches, multiple imputation is the most commonly used and flexible, particularly when multiple variables have missing values (Barnard &amp; Meng, 1999). Results using any of these approaches should be compared with those from complete case analyses, and important differences discussed. The plausibility of assumptions made in missing data analyses is generally unverifiable. In particular it is impossible to prove that data are MAR, rather than MNAR. Such analyses are therefore best viewed in the spirit of sensitivity analysis (see items 12e and 17). (Vandenbroucke et al., 2007) Explanation 12d Case-Control In individually matched case-control studies a crude analysis of the odds ratio, ignoring the matching, usually leads to an estimation that is biased towards unity (see box 2). A matched analysis is therefore often necessary. This can intuitively be understood as a stratified analysis: each case is seen as one stratum with his or her set of matched controls. The analysis rests on considering whether the case is more often exposed than the controls, despite having made them alike regarding the matching variables. Investigators can do such a stratified analysis using the Mantel-Haenszel method on a ‘matched’ 2 by 2 table. In its simplest form the odds ratio becomes the ratio of pairs that are discordant for the exposure variable. If matching was done for variables like age and sex that are universal attributes, the analysis needs not retain the individual, person-to-person matching: a simple analysis in categories of age and sex is sufficient. (K. J. Rothman et al., 1998b) For other matching variables, such as neighborhood, sibship, or friendship, however, each matched set should be considered its own stratum. In individually matched studies, the most widely used method of analysis is conditional logistic regression, in which each case and their controls are considered together. The conditional method is necessary when the number of controls varies among cases, and when, in addition to the matching variables, other variables need to be adjusted for. To allow readers to judge whether the matched design was appropriately taken into account in the analysis, we recommend that authors describe in detail what statistical methods were used to analyse the data. If taking the matching into account does have little effect on the estimates, authors may choose to present an unmatched analysis. (Vandenbroucke et al., 2007) Explanation 12d Cross-sectional Most cross-sectional studies use a pre-specified sampling strategy to select participants from a source population. Sampling may be more complex than taking a simple random sample, however. It may include several stages and clustering of participants (eg, in districts or villages). Proportionate stratification may ensure that subgroups with a specific characteristic are correctly represented. Disproportionate stratification may be useful to over-sample a subgroup of particular interest. An estimate of association derived from a complex sample may be more or less precise than that derived from a simple random sample. Measures of precision such as standard error or confidence interval should be corrected using the design effect, a ratio measure that describes how much precision is gained or lost if a more complex sampling strategy is used instead of simple random sampling. (Lohr, 1999) Most complex sampling techniques lead to a decrease of precision, resulting in a design effect greater than 1. We advise that authors clearly state the method used to adjust for complex sampling strategies so that readers may understand how the chosen sampling method influenced the precision of the obtained estimates. For instance, with clustered sampling, the implicit trade-off between easier data collection and loss of precision is transparent if the design effect is reported. In the example, the calculated design effects of 1.9 for men indicates that the actual sample size would need to be 1.9 times greater than with simple random sampling for the resulting estimates to have equal precision. (Vandenbroucke et al., 2007) Explanation 12e Sensitivity analyses are useful to investigate whether or not the main results are consistent with those obtained with alternative analysis strategies or assumptions. (K. Rothman &amp; Greenland, 1998a) Issues that may be examined include the criteria for inclusion in analyses, the definitions of exposures or outcomes, (Custer et al., 2006) which confounding variables merit adjustment, the handling of missing data, (Dunn et al., 2001; Wakefield et al., 2000) possible selection bias or bias from inaccurate or inconsistent measurement of exposure, disease and other variables, and specific analysis choices, such as the treatment of quantitative variables (see item 11). Sophisticated methods are increasingly used to simultaneously model the influence of several biases or assumptions. (Greenland, 2003; Lash &amp; Fink, 2003; Phillips, 2003) In 1959 Cornfield et al famously showed that a relative risk of 9 for cigarette smoking and lung cancer was extremely unlikely to be due to any conceivable confounder, since the confounder would need to be at least nine times as prevalent in smokers as in non-smokers. (Cornfield et al., 1959) This analysis did not rule out the possibility that such a factor was present, but it did identify the prevalence such a factor would need to have. The same approach was recently used to identify plausible confounding factors that could explain the association between childhood leukemia and living near electric power lines. (Langholz, 2001) More generally, sensitivity analyses can be used to identify the degree of confounding, selection bias, or information bias required to distort an association. One important, perhaps under recognized, use of sensitivity analysis is when a study shows little or no association between an exposure and an outcome and it is plausible that confounding or other biases toward the null are present. (Vandenbroucke et al., 2007) Field-specific guidance Genetic association studies (Little et al., 2009) - State whether Hardy-Weinberg equilibrium was considered and, if so, how - Describe any methods used for inferring genotypes or haplotypes Nutritional data (Lachat et al., 2016) - Describe and justify the method for energy adjustments, intake modeling, and use of weighting factors, if applicable Response-driven sampling (White et al., 2015) - Report any criteria used to support statements on whether estimator conditions or assumptions were appropriate - Explain how seeds were handled in analysis Rheumatology(Zavada et al., 2014) - Deﬁne and justify the risk window. Whenever possible, categorise as (1) on drug, (2) on drug + lag window or (3) ever treated - The use of multiple risk attribution models and lag windows is encouraged if appropriate, but needs to be accompanied by a description of numbers and relative risks for each model Routinely collected health data (Benchimol et al., 2015) - Authors should describe the extent to which the investigators had access to the database population used to create the study population Seroepidemiologic studies for influenza (Horby et al., 2017) - If relevant, report methods used to account for the probability of seropositivity or seroconversion if infected, and to account for decay in antibody titers over time - Describe the sample type—serum or plasma. If plasma is used, specify the anticoagulant used (heparin, sodium citrate, EDTA, etc.) - Describe the specimen storage conditions (4°C, −20 °C, −80 °C). If frozen prior to the analysis, describe the time to freezing and the number of freeze/thaw cycles prior to testing - Specify the assay type (e.g., hemagglutination inhibition; virus neutralization/microneutralization; ELISA; other) and methods used to determine the endpoint titer - Reference a previously published, CONSISE consensus serologic assay or WHO protocol if used, and any modifications of the protocol. If a previously published protocol is not used, provide full details in supplementary materials - State what is known about the determinants of the variability of the antibody detection assay being used - Specify the antigen(s) used in the assay, including virus strain name, subtype, lineage or clade, with standardized nomenclature and reference; specify whether live virus or inactivated virus was used (where applicable) - Report if antigen(s) from potentially cross-reactive pathogens/strains were used in order to identify cross-reactivity, and specify which antigen was used, including virus name, subtype, strain, lineage and clade, with standardized nomenclature and reference - If red blood cells were used for a hemagglutinin inhibition assay, specify the animal species from which they were obtained and concentration (v/v) used - Describe positive and negative controls used - Describe starting and end dilutions - Specify laboratory biosafety conditions - Specify whether replication was performed, and if so, the acceptable replication parameters - Specify whether a confirmatory assay was performed and all specifics of this assay, at the same level of detail - Specify international standards used, if appropriate Resources Do you know of any good guidance or resources related to this item? Suggest them via comments below, Twitter, GitHub, or e-mail. Bland, J. M., &amp; Altman, D. G. (1997). Statistics notes: Cronbach’s alpha. BMJ, 314(7080), 572. https://doi.org/10.1136/bmj.314.7080.572 (Bland &amp; Altman, 1997) - BMJ Publishing Group. (2018). How to estimate the effect of treatment duration on survival outcomes using observational data. BMJ, 360, k182. https://doi.org/10.1136/bmj.k182 (British Medical Journal Publishing, 2018) - Cronbach, L. J. (1951). Coefficient alpha and the internal structure of tests. Psychometrika, 16(3), 297–334. https://doi.org/10.1007/BF02310555 (Cronbach, 1951) - Gamble, C., Krishan, A., Stocken, D., Lewis, S., Juszczak, E., Dore, C., Williamson, P. R., Altman, D. G., Montgomery, A., Lim, P., Berlin, J., Senn, S., Day, S., Barbachano, Y., &amp; Loder, E. (2017). Guidelines for the Content of Statistical Analysis Plans in Clinical Trials. JAMA, 318(23), 2337–2343. https://doi.org/10.1001/jama.2017.18556 (Gamble et al., 2017) - Greenland, S., Senn, S. J., Rothman, K. J., Carlin, J. B., Poole, C., Goodman, S. N., &amp; Altman, D. G. (2016). Statistical tests, P values, confidence intervals, and power: A guide to misinterpretations. European Journal of Epidemiology, 31, 337–350. https://doi.org/10.1007/s10654-016-0149-3 (Greenland et al., 2016) - Ibrahim, J. G., &amp; Molenberghs, G. (2009). Missing data methods in longitudinal studies: a review. Test (Madrid, Spain), 18(1), 1–43. doi:10.1007/s11749-009-0138-x (Ibrahim &amp; Molenberghs, 2009) - Knol, M. J., Egger, M., Scott, P., Geerlings, M. I., &amp; Vandenbroucke, J. P. (2009). When One Depends on the Other: Reporting of Interaction in Case-Control and Cohort Studies. Epidemiology, 20(2), 161. https://doi.org/10.1097/EDE.0b013e31818f6651 (Knol et al., 2009) - Lesko, C. R., Edwards, J. K., Cole, S. R., Moore, R. D., &amp; Lau, B. (2018). When to Censor? American Journal of Epidemiology, 187(3), 623–632. https://doi.org/10.1093/aje/kwx281 (Lesko et al., 2018) - Mansournia, M. A., Etminan, M., Danaei, G., Kaufman, J. S., &amp; Collins, G. (2017). Handling time varying confounding in observational research. BMJ, 359. https://doi.org/10.1136/bmj.j4587 (Mansournia et al., 2017) - Smeden, M. van, Moons, K. G., Groot, J. A. de, Collins, G. S., Altman, D. G., Eijkemans, M. J., &amp; Reitsma, J. B. (2018). Sample size for binary logistic prediction models: Beyond events per variable criteria. Statistical Methods in Medical Research, 0962280218784726. https://doi.org/10.1177/0962280218784726 (Smeden et al., 2018) - Smeden, M. van, Lash, T. L., &amp; Groenwold, R. H. H. (2019). Reflection on modern methods: Five myths about measurement error in epidemiological research. International Journal of Epidemiology, dyz251. https://doi.org/10.1093/ije/dyz251 (Smeden et al., 2019) References "],
["results-participants-13.html", "Results: Participants (13) Explanation 13a Example 13a Explanation 13b Example 13b Explanation 13c Example 13c Field-specific guidance Resources", " Results: Participants (13) The items from STROBE state that you should report: - Report the numbers of individuals at each stage of the study e.g., numbers potentially eligible, examined for eligibility, confirmed eligible, included in the study, completing follow up, and analyzed (13a) - Give reasons for nonparticipation at each stage (13b) - Consider use of a flow diagram (13c) The Results section should give a factual account of what was found, from the recruitment of study participants, the description of the study population to the main results and ancillary analyses. It should be free of interpretations and discursive text reflecting the authors’ views and opinions. (Vandenbroucke et al., 2007) Some key items to consider adding: - The reasons for loss of data and/or participants at each stage - The number of individuals excluded based on missing, incomplete, or implausible data - The estimated design effect for outcomes of interest - The use of an organizational structure diagram if you have dealing with related or matched participants (e.g., families, cases and controls) Explanation 13a Detailed information on the process of recruiting study participants is important for several reasons. Those included in a study often differ in relevant ways from the target population to which results are applied. This may result in estimates of prevalence or incidence that do not reflect the experience of the target population. For example, people who agreed to participate in a postal survey of sexual behaviour attended church less often, had less conservative sexual attitudes and earlier age at first sexual intercourse, and were more likely to smoke cigarettes and drink alcohol than people who refused. (Dunne et al., 1997) These differences suggest that postal surveys may overestimate sexual liberalism and activity in the population. Such response bias (see box 3) can distort exposure-disease associations if associations differ between those eligible for the study and those included in the study. As another example, the association between young maternal age and leukemia in offspring, which has been observed in some case-control studies, (Cnattingius et al., 1995; Schulz et al., 1999) was explained by differential participation of young women in case and control groups. Young women with healthy children were less likely to participate than those with unhealthy children.(Schulz, 2003) Although low participation does not necessarily compromise the validity of a study, transparent information on participation and reasons for nonparticipation is essential. Also, as there are no universally agreed definitions for participation, response or follow-up rates, readers need to understand how authors calculated such proportions. (Slattery et al., 1995) Ideally, investigators should give an account of the numbers of individuals considered at each stage of recruiting study participants, from the choice of a target population to the inclusion of participants’ data in the analysis. Depending on the type of study, this may include the number of individuals considered to be potentially eligible, the number assessed for eligibility, the number found to be eligible, the number included in the study, the number examined, the number followed up and the number included in the analysis. Information on different sampling units may be required, if sampling of study participants is carried out in two or more stages as in the example above (multistage sampling). In case-control studies, we advise that authors describe the flow of participants separately for case and control groups. (Schulz, 2002) Controls can sometimes be selected from several sources, including, for example, hospitalized patients and community dwellers. In this case, we recommend a separate account of the numbers of participants for each type of control group. Olson and colleagues proposed useful reporting guidelines for controls recruited through random-digit dialling and other methods. (Olson et al., 2002) A recent survey of epidemiological studies published in 10 general epidemiology, public health and medical journals found that some information regarding participation was provided in 47 of 107 case-control studies (59%), 49 of 154 cohort studies (32%), and 51 of 86 cross-sectional studies (59%). (Morton et al., 2006) Incomplete or absent reporting of participation and nonparticipation in epidemiological studies was also documented in two other surveys of the literature. (Pocock et al., 2004; Tooth et al., 2005) Finally, there is evidence that participation in epidemiological studies may have declined in recent decades, (Morton et al., 2006; Olson et al., 2001) which underscores the need for transparent reporting. (Sandler, 2002; Vandenbroucke et al., 2007) Example 13a “Of the 105 freestanding bars and taverns sampled, 13 establishments were no longer in business and 9 were located in restaurants, leaving 83 eligible businesses. In 22 cases, the owner could not be reached by telephone despite 6 or more attempts. The owners of 36 bars declined study participation. (…) The 25 participating bars and taverns employed 124 bartenders, with 67 bartenders working at least 1 weekly daytime shift. Fifty-four of the daytime bartenders (81%) completed baseline interviews and spirometry; 53 of these subjects (98%) completed follow-up.” (Eisner et al., 1998; Vandenbroucke et al., 2007) Explanation 13b Explaining the reasons why people no longer participated in a study or why they were excluded from statistical analyses helps readers judge whether the study population was representative of the target population and whether bias was possibly introduced. For example, in a cross-sectional health survey, non-participation due to reasons unlikely to be related to health status (for example, the letter of invitation was not delivered because of an incorrect address) will affect the precision of estimates but will probably not introduce bias. Conversely, if many individuals opt out of the survey because of illness, or perceived good health, results may underestimate or overestimate the prevalence of ill health in the population. (Vandenbroucke et al., 2007) Example 13b “The main reasons for non-participation were the participant was too ill or had died before interview (cases 30%, controls &lt; 1%), nonresponse (cases 2%, controls 21%), refusal (cases 10%, controls 29%), and other reasons (refusal by consultant or general practitioner, non-English speaking, mental impairment) (cases 7%, controls 5%).” (Hepworth et al., 2006; Vandenbroucke et al., 2007) Explanation 13c An informative and well-structured flow diagram can readily and transparently convey information that might otherwise require a lengthy description,(Egger et al., 2001) as in the example above. The diagram may usefully include the main results, such as the number of events for the primary outcome. While we recommend the use of a flow diagram, particularly for complex observational studies, we do not propose a specific format for the diagram. (Vandenbroucke et al., 2007) Example 13c Flow diagram from Hay et al. (Hay et al., 2003) https://doi.org/10.1371/journal.pmed.0040297.g001 Field-specific guidance Genetic association studies (Little et al., 2009) - Report numbers of individuals in whom genotyping was attempted and numbers of individuals in whom genotyping was successful Infectious disease molecular epidemiology (Field et al., 2014) - Report numbers of participants and samples at each stage of the study, including the number of samples obtained, the number typed, and the number yielding data - If the study investigates groups of genetically indistinguishable pathogens (molecular clusters), state the sampling fraction, the distribution of cluster sizes, and the study population turnover, if known Medical abortion (Creinin &amp; Chen, 2016) - Report the number of participants who started medical abortion treatment and the number who did not complete any follow-up for each cohort and by gestational age - Report the number of participants used in the denominator for outcome evaluation for each cohort and by gestational age, which most commonly will be the number of women with any follow-up - Include a description of the number of women who used the drug(s) as planned in the protocol (treatment adherence) - When more than one drug is used (e.g. mifepristone and a prostaglandin analog), the actual time interval between the agents should be reported, preferably in hours Neonatal infections (Fitchett et al., 2016) - See ﬁgure 2 for suggested components of a ﬂow diagram for neonatal infections Response-driven sampling (White et al., 2015) - Report number of coupons issued and returned - Report number of recruits by seed and number of RDS recruitment waves for each seed. Consider showing graph of entire recruitment network - Report recruitment challenges (e.g., commercial exchange of coupons, imposters, duplicate recruits) and how addressed Routinely collected health data (Benchimol et al., 2015) - Describe in detail the selection of the persons included in the study (i.e., study population selection), including ﬁltering based on data quality, data availability, and linkage. The selection of included persons can be described in the text and/or by means of the study ﬂow diagram Veterinary epidemiology (O’Connor et al., 2016) - Report the numbers of owners/managers and animals at each stage of study and at each relevant level of organization - e.g, numbers eligible, included in the study, completing follow-up, and analyzed - Give reasons for non-participation at each stage and at each relevant level of organization Resources Do you know of any good guidance or resources related to this item? Suggest them via comments below, Twitter, GitHub, or e-mail. References "],
["results-descriptive-data-14.html", "Results: Descriptive Data (14) Explanation 14a Example 14a Explanation 14b Example 14b Explanation 14c Example 14c Field-specific guidance Resources", " Results: Descriptive Data (14) The items from STROBE state that you should report: - Give characteristics of study participants (e.g., demographic, clinical, social) and information on exposures and potential confounders - Indicate the number of participants with missing data for each variable of interest - Cohort study Summarize follow-up time (e.g., average and total amount) Some key items to consider adding: - Give the distribution of measurements (including mean, median, range and variance) - Average treatment duration for all groups - Report any subjects that changed exposure status, those eligible for follow-up, those who completed follow-up and numbers remaining on treatment and/or in analysis at relevant time points during follow-up (eg, at yearly intervals) - Summarize follow-up time (e.g, average and total amount), if appropriate to the study design - Consider presenting number exposed, outcomes, and relatives risks as tabular or graphical presentations - Give unweighted sample size and percentages - Discuss estimated population proportions or means with estimated precision (e.g., 95% confidence interval) Explanation 14a Readers need descriptions of study participants and their exposures to judge the generalizability of the findings. Information about potential confounders, including whether and how they were measured, influences judgments about study validity. We advise authors to summarize continuous variables for each study group by giving the mean and standard deviation, or when the data have an asymmetrical distribution, as is often the case, the median and percentile range (eg, 25th and 75th percentiles). Variables that make up a small number of ordered categories (such as stages of disease I to IV) should not be presented as continuous variables; it is preferable to give numbers and proportions for each category (see also box 4). In studies that compare groups, the descriptive characteristics and numbers should be given by group, as in the example above. Inferential measures such as standard errors and confidence intervals should not be used to describe the variability of characteristics, and significance tests should be avoided in descriptive tables. Also, P values are not an appropriate criterion for selecting which confounders to adjust for in analysis; even small differences in a confounder that has a strong effect on the outcome can be important. (Dales &amp; Ury, 1978; Maldonado &amp; Greenland, 1993) In cohort studies, it may be useful to document how an exposure relates to other characteristics and potential confounders. Authors could present this information in a table with columns for participants in two or more exposure categories, which permits to judge the differences in confounders between these categories. In case-control studies potential confounders cannot be judged by comparing cases and controls. Control persons represent the source population and will usually be different from the cases in many respects. For example, in a study of oral contraceptives and myocardial infarction, a sample of young women with infarction more often had risk factors for that disease, such as high serum cholesterol, smoking and a positive family history, than the control group.146 This does not influence the assessment of the effect of oral contraceptives, as long as the prescription of oral contraceptives was not guided by the presence of these risk factors - eg, because the risk factors were only established after the event (see also box 5). In case-control studies the equivalent of comparing exposed and non-exposed for the presence of potential confounders (as is done in cohorts) can be achieved by exploring the source population of the cases: if the control group is large enough and represents the source population, exposed and unexposed controls can be compared for potential confounders. (K. Rothman &amp; Greenland, 1998a, 1998c) Example 14a Characteristics of the Study Base at Enrolment, Castellana G (Italy), 1985–1986 https://doi.org/10.1371/journal.pmed.0040297.t002 Explanation 14b As missing data may bias or affect generalizability of results, authors should tell readers amounts of missing data for exposures, potential confounders, and other important characteristics of patients (see also item 12c and box 6). In a cohort study, authors should report the extent of loss to follow-up (with reasons), since incomplete follow-up may bias findings (see also items 12d and 13). (Clark et al., 2002) We advise authors to use their tables and figures to enumerate amounts of missing data. Example 14b Symptom End Points Used in Survival Analysis https://doi.org/10.1371/journal.pmed.0040297.t003 Explanation 14c Readers need to know the duration and extent of follow- up for the available outcome data. Authors can present a summary of the average follow-up with either the mean or median follow-up time or both. The mean allows a reader to calculate the total number of person-years by multiplying it with the number of study participants. Authors also may present minimum and maximum times or percentiles of the distribution to show readers the spread of follow-up times. They may report total person-years of follow-up or some indication of the proportion of potential data that was captured. (Clark et al., 2002) All such information may be presented separately for participants in two or more exposure categories. Almost half of 132 articles in cancer journals (mostly cohort studies) did not give any summary of length of follow-up. (Altman et al., 1995; Vandenbroucke et al., 2007) Example 14c “During the 4366 person-years of follow-up (median 5.4, maximum 8.3 years), 265 subjects were diagnosed as having dementia, including 202 with Alzheimer’s disease” (Qiu et al., 2004). Field-specific guidance Anti-microbial stewardship programs (Tacconelli et al., 2016) - Specify among the exposure: previous stay in long-term care facilities, nursing home and other healthcare settings Genetic association studies (Little et al., 2009) - Consider giving information by genotype Infectious disease molecular epidemiology (Field et al., 2014) - Give information by strain type if appropriate, with use of standardised nomenclature Neonatal infections (Fitchett et al., 2016) - Describe maternal infections (clinical or on screening—eg, group B streptococcus or HIV) or risk factors for infection (eg, premature rupture of membranes, peripartum fever) - Describe key neonatal characteristics, including sex, postnatal and gestational age categories (range and median), birthweight categories (range and median), birth place, feeding (breastmilk or other), and comorbidities - Report data on occurrence of individual signs, according to case deﬁnitions - Give proportion of mothers and neonates with peripartum antibiotic exposure (with or without pre-admission exposusure for neonates) - Report details of antimicrobial drugs (or supportive care) given during the study Nutritional data (Lachat et al., 2016) - Give the distribution of participant characteristics across the exposure variables if applicable. Specify if food consumption of total population or consumers only were used to obtain results Simulation-based research (Cheng et al., 2016) - In describing characteristics of study participants, include their previous experience with simulation and other relevant features as related to the intervention(s) Veterinary epidemiology (O’Connor et al., 2016) - Give characteristics of study participants (e.g, demographic, clinical, social) and information on exposures and potential confounders by group and level of organization, if applicable - Indicate number of participants with missing data for each variable of interest and at all relevant levels of organization Resources Do you know of any good guidance or resources related to this item? Suggest them via comments below, Twitter, GitHub, or e-mail. References "],
["results-outcome-data-15.html", "Results: Outcome Data (15) Explanation Examples Field-specific guidance Resources", " Results: Outcome Data (15) The items from STROBE state that you should report: - Cohort study: Report numbers of outcome events or summary measures over time - Case-control study: Report numbers in each exposure category, or summary measures of exposure - Cross-sectional study: Report numbers of outcome events or summary measures Some key items to consider adding: - Consider the use of a tabular or graphical presentation (Kaplan–Meier, cumulative incidence plot) of the outcome over time for the exposed and comparison cohort - Report outcomes at all relevant levels of organization - For proportions and rates, report the numerator and denominator - For continuous outcomes, report the number of observations and a measure of variability Explanation Before addressing the possible association between exposures (risk factors) and outcomes, authors should report relevant descriptive data. It may be possible and meaningful to present measures of association in the same table that presents the descriptive data (see item 14a). In a cohort study with events as outcomes, report the numbers of events for each outcome of interest. Consider reporting the event rate per person-year of follow-up. If the risk of an event changes over follow-up time, present the numbers and rates of events in appropriate intervals of follow-up or as a Kaplan-Meier life table or plot. It might be preferable to show plots as cumulative incidence that go up from 0% rather than down from 100%, especially if the event rate is lower than, say, 30%. (Pocock et al., 2002) Consider presenting such information separately for participants in different exposure categories of interest. If a cohort study is investigating other time-related outcomes (eg, quantitative disease markers such as blood pressure), present appropriate summary measures (eg, means and standard deviations) over time, perhaps in a table or figure. For cross-sectional studies, we recommend presenting the same type of information on prevalent outcome events or summary measures. For case-control studies, the focus will be on reporting exposures separately for cases and controls as frequencies or quantitative summaries. (Sasieni, 1992) For all designs, it may be helpful also to tabulate continuous outcomes or exposures in categories, even if the data are not analyzed as such. (Vandenbroucke et al., 2007) Examples Cohort example Rates of HIV-1 Seroconversion by Selected Sociodemographic Variables: 1990–1993 https://doi.org/10.1371/journal.pmed.0040297.t004 Case-Control example Exposure among Liver Cirrhosis Cases and Controls https://doi.org/10.1371/journal.pmed.0040297.t006 Cross-sectional Example Prevalence of Current Asthma and Diagnosed Hay Fever by Average Alternaria alternata Antigen Level in the Household https://doi.org/10.1371/journal.pmed.0040297.t007 Field-specific guidance Genetic association studies (Little et al., 2009) - Cohort: Report outcomes (phenotypes) for each genotype category over time - Report numbers in each genotype category - Cross-sectional: Report outcomes (phenotypes) for each genotype category Neonatal infections (Fitchett et al., 2016) - Report the number (and the proportion) of samples microbiologically tested (including lumbar punctures for meningitis cases); the number (and the proportion) that were positive (including thresholds for detection, where applicable); all isolates obtained (including clinically signiﬁcant and nonsigniﬁcant); and antimicrobial susceptibilities of pathogens, where done - Report the number (and the proportion) of babies with microbiologically proven infection (and number of infections per baby), and include this in the ﬂ ow chart (see ﬁgure 2) - Report infections by day, for days 0–6. State age categories, if used, deﬁning early-onset and late-onset infection (eg, &lt;72 h and ≥72 h, respectively) - Report deaths and any subanalyses by risk groups Resources Do you know of any good guidance or resources related to this item? Suggest them via comments below, Twitter, GitHub, or e-mail. References "],
["results-main-results-16.html", "Results: Main Results (16) Explanation 16a Examples 16a Explanation 16b Example 16b Explanation 16c Example 16c Box 7. Measures of association, effect and impact Field-specific guidance Resources", " Results: Main Results (16) The items from STROBE state that you should report: - Give unadjusted estimates and, if applicable, confounder-adjusted estimates and their precision (e.g., 95% confidence interval). Make clear which confounders were adjusted for and why they were included - Report category boundaries when continuous variables were categorized - If relevant, consider translating estimates of relative risk into absolute risk for a meaningful time period Some key items to consider adding: - Present both relative risks and absolute measures such as event rates per person-time, risk differences or numbers needed to treat/numbers needed to harm - Present results per time period of follow-up, if applicable, so as to indicate any time dependence of the association between exposure and outcome - Report methods to standardize the results from the study sample to the target population - For assessments involving &gt;1 rater, interrater reliability should be reported - Give unadjusted estimates and, if applicable, adjusted estimates and their precision (e.g, 95% conﬁdence interval). Make clear which confounders and interactions were adjusted. Report all relevant parameters that were part of the model - Report results of any adjustments for multiple comparisons Explanation 16a In many situations, authors may present the results of unadjusted or minimally adjusted analyses and those from fully adjusted analyses. We advise giving the unadjusted analyses together with the main data, for example the number of cases and controls that were exposed or not. This allows the reader to understand the data behind the measures of association (see also item 15). For adjusted analyses, report the number of persons in the analysis, as this number may differ because of missing values in covariates (see also item 12c). Estimates should be given with confidence intervals. Readers can compare unadjusted measures of association with those adjusted for potential confounders and judge by how much, and in what direction, they changed. Readers may think that ‘adjusted’ results equal the causal part of the measure of association, but adjusted results are not necessarily free of random sampling error, selection bias, information bias, or residual confounding (see box 5). Thus, great care should be exercised when interpreting adjusted results, as the validity of results often depends crucially on complete knowledge of important confounders, their precise measurement, and appropriate specification in the statistical model (see also item 20). (Christenfeld et al., 2004; Smith &amp; Phillips, 1990) Authors should explain all potential confounders considered, and the criteria for excluding or including variables in statistical models. Decisions about excluding or including variables should be guided by knowledge, or explicit assumptions, on causal relations. Inappropriate decisions may introduce bias, for example by including variables that are in the causal pathway between exposure and disease (unless the aim is to asses how much of the effect is carried by the intermediary variable). If the decision to include a variable in the model was based on the change in the estimate, it is important to report what change was considered sufficiently important to justify its inclusion. If a ‘backward deletion’ or ‘forward inclusion’ strategy was used to select confounders, explain that process and give the significance level for rejecting the null hypothesis of no confounding. Of note, we and others do not advise selecting confounders based solely on statistical significance testing. (Greenland &amp; Neutra, 1980; Robins, 2001; K. Rothman &amp; Greenland, 1998c) Recent studies of the quality of reporting of epidemiological studies found that confidence intervals were reported in most articles. (Pocock et al., 2004) However, few authors explained their choice of confounding variables. (Pocock et al., 2004; Tooth et al., 2005; Vandenbroucke et al., 2007) Examples 16a Example 1 “We initially considered the following variables as potential confounders by Mantel-Haenszel stratified analysis: (…) The variables we included in the final logistic regression models were those (…) that produced a 10% change in the odds ratio after the Mantel-Haenszel adjustment” (Lee et al., 2002; Vandenbroucke et al., 2007). Example 2 Relative Rates of Rehospitalisation by Treatment in Patients in Community Care after First Hospitalisation due to Schizophrenia and Schizoaffective Disorder https://doi.org/10.1371/journal.pmed.0040297.t008 (Tiihonen et al., 2006; Vandenbroucke et al., 2007) Explanation 16b Categorizing continuous data has several important implications for analysis (see box 4) and also affects the presentation of results. In tables, outcomes should be given for each exposure category, for example as counts of persons at risk, person-time at risk, if relevant separately for each group (eg, cases and controls). Details of the categories used may aid comparison of studies and meta-analysis. If data were grouped using conventional cut-points, such as body mass index thresholds, (World Health Organization, 2020) (updated reference) group boundaries (ie, range of values) can be derived easily, except for the highest and lowest categories. If quantilederived categories are used, the category boundaries cannot be inferred from the data. As a minimum, authors should report the category boundaries; it is helpful also to report the range of the data and the mean or median values within categories. (Vandenbroucke et al., 2007) Example 16b Report category boundaries when continuous variables were categorised. Polychlorinated Biphenyls in Cord Serum https://doi.org/10.1371/journal.pmed.0040297.t005 (Sagiv et al., 2007; Vandenbroucke et al., 2007) Explanation 16c The results from studies examining the association between an exposure and a disease are commonly reported in relative terms, as ratios of risks, rates or odds (see box 8). Relative measures capture the strength of the association between an exposure and disease. If the relative risk is a long way from 1 it is less likely that the association is due to confounding. 164,165 Relative effects or associations tend to be more consistent across studies and populations than absolute measures, but what often tends to be the case may be irrelevant in a particular instance. For example, similar relative risks were obtained for the classic cardiovascular risk factors for men living in Northern Ireland, France, the USA and Germany, despite the fact that the underlying risk of coronary heart disease varies substantially between these countries. (Empana et al., 2003; Tunstall-Pedoe et al., 1999) In contrast, in a study of hypertension as a risk factor for cardiovascular disease mortality, the data were more compatible with a constant rate difference than with a constant rate ratio. (Cambien et al., 1985) Widely used statistical models, including logistic (Hosmer et al., 1991) and proportional hazards (Cox) regression (Tibshirani, 1982) are based on ratio measures. In these models, only departures from constancy of ratio effect measures are easily discerned. Nevertheless, measures which assess departures from additivity of risk differences, such as the Relative Excess Risk from Interaction (RERI, see item 12b and box 8), can be estimated in models based on ratio measures. In many circumstances, the absolute risk associated with an exposure is of greater interest than the relative risk. For example, if the focus is on adverse effects of a drug, one will want to know the number of additional cases per unit time of use (eg, days, weeks, or years). The example gives the additional number of breast cancer cases per 1000 women who used hormone-replacement therapy for 10 years. (Beral, 2003) Measures such as the attributable risk or population attributable fraction may be useful to gauge how much disease can be prevented if the exposure is eliminated. They should preferably be presented together with a measure of statistical uncertainty (eg, confidence intervals, as in the example). Authors should be aware of the strong assumptions made in this context, including a causal relationship between a risk factor and disease (also see [box 7][Box 7. Measures of association, effect and impact)]. (Rockhill et al., 1998) Because of the semantic ambiguity and complexities involved, authors should report in detail what methods were used to calculate attributable risks, ideally giving the formulae used. (Uter &amp; Pfahlberg, 2001) A recent survey of abstracts of 222 articles published in leading medical journals found that in 62% of abstracts of randomized trials including a ratio measure absolute risks were given, but only in 21% of abstracts of cohort studies. (Schwartz et al., 2006) A free text search of Medline 1966 to 1997 showed that 619 items mentioned attributable risks in the title or abstract, compared to 18,955 using relative risk or odds ratio, for a ratio of 1 to 31. (Nakayama et al., 1998; Vandenbroucke et al., 2007) Example 16c “10 years’ use of HRT [hormone replacement therapy] is estimated to result in five (95% CI 3–7) additional breast cancers per 1000 users of oestrogen-only preparations and 19 (15–23) additional cancers per 1000 users of oestrogen-progestagen combinations” (Beral, 2003; Vandenbroucke et al., 2007). Box 7. Measures of association, effect and impact Observational studies may be solely done to describe the magnitude and distribution of a health problem in the population. They may examine the number of people who have a disease at a particular time (prevalence), or that develop a disease over a defined period (incidence). The incidence may be expressed as the proportion of people developing the disease (cumulative incidence) or as a rate per person-time of follow-up (incidence rate). Specific terms are used to describe different incidences; amongst others, mortality rate, birth rate, attack rate, or case fatality rate. Similarly, terms like point prevalence and period, annual or lifetime prevalence are used to describe different types of prevalence (Last, 2000). Other observational studies address cause-effect relationships. Their focus is the comparison of the risk, rate or prevalence of the event of interest between those exposed and those not exposed to the risk factor under investigation. These studies often estimate a ‘relative risk’, which may stand for risk ratios (ratios of cumulative incidences) as well as rate ratios (ratios of incidence rates). In case-control studies only a fraction of the source population (the controls) are included. Results are expressed as the ratio of the odds of exposure among cases and controls. This odds ratio provides an estimate of the risk or rate ratio depending on the sampling of cases and controls (see also Box 1) (Cornfield, 1951; Pearce, 1993). The prevalence ratio or prevalence odds ratio from cross-sectional studies may be useful in some situations (K. Rothman &amp; Greenland, 1998b). Expressing results both in relative and absolute terms may often be helpful. For example, in a study of male British doctors the incidence rate of death from lung cancer over 50 years of follow-up was 249 per 100,000 per year among smokers, compared to 17 per 100,000 per year among non-smokers: a rate ratio of 14.6 (249/17) (Doll et al., 1954). For coronary heart disease (CHD), the corresponding rates were 1001 and 619 per 100,000 per year, for a rate ratio of 1.61 (1001/619). The effect of smoking on death appears much stronger for lung cancer than for CHD. The picture changes when we consider the absolute effects of smoking. The difference in incidence rates was 232 per 100,000 per year (249 − 17) for lung cancer and 382 for CHD (1001 − 619). Therefore, among doctors who smoked, smoking was more likely to cause death from CHD than from lung cancer. How much of the disease burden in a population could be prevented by eliminating an exposure? Global estimates have been published for smoking: according to one study 91% of all lung cancers, 40% of CHD and 33% of all deaths among men in 2000 were attributed to smoking (Ezzati &amp; Lopez, 2003). The population attributable fraction is generally defined as the proportion of cases caused by a particular exposure, but several concepts (and no unified terminology) exist, and incorrect approaches to adjust for other factors are sometimes used (S, n.d.-a; Uter &amp; Pfahlberg, 2001). What are the implications for reporting? The relative measures emphasise the strength of an association, and are most useful in etiologic research. If a causal relationship with an exposure is documented and associations are interpreted as effects, estimates of relative risk may be translated into suitable measures of absolute risk in order to gauge the possible impact of public health policies (see item 16c) (Rose, 2001). However, authors should be aware of the strong assumptions made in this context (Rockhill et al., 1998). Care is needed in deciding which concept and method is appropriate for a particular situation. (Vandenbroucke et al., 2007) Field-specific guidance Infectious disease molecular epidemiology (Field et al., 2014) - Consider showing molecular relatedness of strain types by means of a dendrogram or phylogenetic tree Medical abortion (Creinin &amp; Chen, 2016) - Present treatment success for each cohort and by gestational age - Present continuing pregnancies for each cohort and by gestational age - Present reasons for surgical intervention other than continuing pregnancy for each cohort and by gestational age Neonatal infections (Fitchett et al., 2016) - For incidence, give risk per 1000 livebirths, or if alternative denominator used (eg, total births or bed days), deﬁne this clearly Nutritional data (Lachat et al., 2016) - Specify if nutrient intakes are reported with or without inclusion of dietary supplement intake, if applicable Seroepidemiologic studies for influenza (Horby et al., 2017) - Report unadjusted estimates of distribution of titers by age group Resources Do you know of any good guidance or resources related to this item? Suggest them via comments below, Twitter, GitHub, or e-mail. References "],
["results-other-analyses-17.html", "Results: Other Analyses (17) Explanation Examples Box 8. Interaction (effect modification) Field-specific guidance Resources", " Results: Other Analyses (17) The items from STROBE state that you should report: - Report other analyses done e.g., analyses of subgroups and interactions, and sensitivity analyses Some key items to consider adding: - Consider performing analyses to explore possible effect modiﬁcation - Consider performing sensitivity/robustness analyses for differing deﬁnitions of exposure and outcome or different statistical models - If detailed results are available elsewhere, state how they can be accessed - Report exclusion of misreporters, outliers, and data imputation Explanation In addition to the main analysis other analyses are often done in observational studies. They may address specific subgroups, the potential interaction between risk factors, the calculation of attributable risks, or use alternative definitions of study variables in sensitivity analyses. There is debate about the dangers associated with subgroup analyses, and multiplicity of analyses in general. (Gotzsche, 2006; Pocock et al., 2004) In our opinion, there is too great a tendency to look for evidence of subgroup-specific associations, or effect-measure modification, when overall results appear to suggest little or no effect. On the other hand, there is value in exploring whether an overall association appears consistent across several, preferably pre-specified subgroups especially when a study is large enough to have sufficient data in each subgroup. A second area of debate is about interesting subgroups that arose during the data analysis. They might be important findings, but might also arise by chance. Some argue that it is neither possible nor necessary to inform the reader about all subgroup analyses done as future analyses of other data will tell to what extent the early exciting findings stand the test of time. (Rothman, 1990) We advise authors to report which analyses were planned, and which were not (see also items 4, 12b and 20). This will allow readers to judge the implications of multiplicity, taking into account the study’s position on the continuum from discovery to verification or refutation. A third area of debate is how joint effects and interactions between risk factors should be evaluated: on additive or multiplicative scales, or should the scale be determined by the statistical model that fits best (see also item 12b and box 8)? A sensible approach is to report the separate effect of each exposure as well as the joint effect – if possible in a table, as in the first example above,[183] or in the study by Martinelli et al. (Martinelli et al., 2003) Such a table gives the reader sufficient information to evaluate additive as well as multiplicative interaction (how these calculations are done is shown in box 8). Confidence intervals for separate and joint effects may help the reader to judge the strength of the data. In addition, confidence intervals around measures of interaction, such as the Relative Excess Risk from Interaction (RERI) relate to tests of interaction or homogeneity tests. One recurrent problem is that authors use comparisons of P values across subgroups, which lead to erroneous claims about an effect modifier. For instance, a statistically significant association in one category (eg, men), but not in the other (eg, women) does not in itself provide evidence of effect modification. Similarly, the confidence intervals for each point estimate are sometimes inappropriately used to infer that there is no interaction whintervals overlap. A more valid inference is achieved by directly evaluating whether the magnitude of an association differs across subgroups. Sensitivity analyses are helpful to investigate the influence of choices made in the statistical analysis, or to investigate the robustness of the findings to missing data or possible biases (see also item 12b). Judgement is needed regarding the level of reporting of such analyses. If many sensitivity analyses were performed, it may be impractical to present detailed findings for them all. It may sometimes be sufficient to report that sensitivity analyses were carried out and that they were consistent with the main results presented. Detailed presentation is more appropriate if the issue investigated is of major concern, or if effect estimates vary considerably.(Anderson et al., 2005; Kyzas et al., 2005) Pocock and colleagues found that 43 out of 73 articles reporting observational studies contained subgroup analyses. The majority claimed differences across groups but only eight articles reported a formal evaluation of interaction (see item 12b).(Pocock et al., 2004; Vandenbroucke et al., 2007) Examples Example 1 Analysis of Oral Contraceptive Use, Presence of Factor V Leiden Allele, and Risk for Venous Thromboembolism https://doi.org/10.1371/journal.pmed.0040297.t009 Example 2 Sensitivity of the Rate Ratio for Cardiovascular Outcome to an Unmeasured Confounder https://doi.org/10.1371/journal.pmed.0040297.t010 Box 8. Interaction (effect modification) The analysis of joint effects Interaction exists when the association of an exposure with the risk of disease differs in the presence of another exposure. One problem in evaluating and reporting interactions is that the effect of an exposure can be measured in two ways: as a relative risk (or rate ratio) or as a risk difference (or rate difference). The use of the relative risk leads to a multiplicative model, while the use of the risk difference corresponds to an additive model (Rothman et al., 1980; Saracci, 1980). A distinction is sometimes made between ‘statistical interaction’ which can be a departure from either a multiplicative or additive model, and ‘biologic interaction’ which is measured by departure from an additive model (Rothman, 2002). However, neither additive nor multiplicative models point to a particular biologic mechanism. Regardless of the model choice, the main objective is to understand how the joint effect of two exposures differs from their separate effects (in the absence of the other exposure). The Human Genomic Epidemiology Network (HuGENet) proposed a lay-out for transparent presentation of separate and joint effects that permits evaluation of different types of interaction (Botto &amp; Khoury, 2001). Data from the study on oral contraceptives and factor V Leiden mutation (Vandenbroucke et al., 1994) were used to explain the proposal, and this example is also used in item 17. Oral contraceptives and factor V Leiden mutation each increase the risk of venous thrombosis; their separate and joint effects can be calculated from the 2 by 4 table (see example 1 for [item 17) where the odds ratio of 1 denotes the baseline of women without Factor V Leiden who do not use oral contraceptives. A difficulty is that some study designs, such as case-control studies, and several statistical models, such as logistic or Cox regression models, estimate relative risks (or rate ratios) and intrinsically lead to multiplicative modelling. In these instances, relative risks can be translated to an additive scale. In example 1 of item 17, the separate odds ratios are 3.7 and 6.9; the joint odds ratio is 34.7. When these data are analysed under a multiplicative model, a joint odds ratio of 25.7 is expected (3.7 × 6.9). The observed joint effect of 34.7 is 1.4 times greater than expected on a multiplicative scale (34.7/25.7). This quantity (1.4) is the odds ratio of the multiplicative interaction. It would be equal to the antilog of the estimated interaction coefficient from a logistic regression model. Under an additive model the joint odds ratio is expected to be 9.6 (3.7 + 6.9 – 1). The observed joint effect departs strongly from additivity: the difference is 25.1 (34.7 – 9.6). When odds ratios are interpreted as relative risks (or rate ratios), the latter quantity (25.1) is the Relative Excess Risk from Interaction (RERI) (K. J. Rothman et al., 1998a). This can be understood more easily when imagining that the reference value (equivalent to OR=1) represents a baseline incidence of venous thrombosis of, say, 1/10 000 women-years, which then increases in the presence of separate and joint exposures. Field-specific guidance Anti-microbial stewardship programs (Tacconelli et al., 2016) - Report subgroup analysis by type of patients and type of microorganism, if applicable Genetic association studies (Little et al., 2009) - If numerous genetic exposures (genetic variants) were examined, summarize results from all analyses undertaken Response-driven sampling (White et al., 2015) - Report other analyses done—for example, analyses of subgroups and interactions, sensitivity analyses, different RDS estimators and definitions of personal network size Resources Do you know of any good guidance or resources related to this item? Suggest them via comments below, Twitter, GitHub, or e-mail. References "],
["discussion-key-results-18.html", "Discussion: Key Results (18) Discussion Explanation Examples Resources", " Discussion: Key Results (18) The items from STROBE state that you should report: - Summarize key results with reference to study objectives Discussion The discussion section addresses the central issues of validity and meaning of the study (Hess, 2004). Surveys have found that discussion sections are often dominated by incomplete or biased assessments of the study’s results and their implications, and rhetoric supporting the authors’ findings (Horton, 2002, 2002). Structuring the discussion may help authors avoid unwarranted speculation and over-interpretation of results while guiding readers through the text (Docherty &amp; Smith, 1999; Perneger &amp; Hudelson, 2004). For example, Annals of Internal Medicine (Internal Medicine, 2007) recommends that authors structure the discussion section by presenting the following: (1) a brief synopsis of the key findings; (2) consideration of possible mechanisms and explanations; (3) comparison with relevant findings from other published studies; (4) limitations of the study; and (5) a brief section that summarizes the implications of the work for practice and research. Others have made similar suggestions (Docherty &amp; Smith, 1999; Hess, 2004). The section on research recommendations and the section on limitations of the study should be closely linked to each other. Investigators should suggest ways in which subsequent research can improve on their studies rather than blandly stating ‘more research is needed’ (Maldonado &amp; Poole, 1999; Phillips, 2001). We recommend that authors structure their discussion sections, perhaps also using suitable (Vandenbroucke et al., 2007) Explanation It is good practice to begin the discussion with a short summary of the main findings of the study. The short summary reminds readers of the main findings and may help them assess whether the subsequent interpretation and implications offered by the authors are supported by the findings. (Vandenbroucke et al., 2007) Examples “We hypothesized that ethnic minority status would be associated with higher levels of cardiovascular disease (CVD) risk factors, but that the associations would be explained substantially by socioeconomic status (SES). Our hypothesis was not confirmed. After adjustment for age and SES, highly significant differences in body mass index, blood pressure, diabetes, and physical inactivity remained between white women and both black and Mexican American women. In addition, we found large differences in CVD risk factors by SES, a finding that illustrates the high-risk status of both ethnic minority women as well as white women with low SES.” (Vandenbroucke et al., 2007; Winkleby et al., 1998) Resources Do you know of any good guidance or resources related to this item? Suggest them via comments below, Twitter, GitHub, or e-mail. References "],
["discussion-limitations-19.html", "Discussion: Limitations (19) Explanation Example Field-specific guidance Resources", " Discussion: Limitations (19) The items from STROBE state that you should report: - Discuss limitations of the study, taking into account sources of potential bias or imprecision. - Discuss both direction and magnitude of any potential bias Some key items to consider adding: - Describe the main limitations of the data sources and assessment methods (e.g., laboratory or collection procedures) used and implications for the interpretation of the ﬁndings - Discuss implications of misclassiﬁcation bias, unmeasured/residual confounding, missing data, and , selection factors for treatment, and changing eligibility over time - Discuss the implications of using data that were not created or collected to answer the speciﬁc research question(s) Explanation The identification and discussion of the limitations of a study are an essential part of scientific reporting. It is important not only to identify the sources of bias and confounding that could have affected results, but also to discuss the relative importance of different biases, including the likely direction and magnitude of any potential bias (see also box 3, item 9). Authors should also discuss any imprecision of the results. Imprecision may arise in connection with several aspects of a study, including the study size (item 10) and the measurement of exposures, confounders and outcomes (item 8). The inability to precisely measure true values of an exposure tends to result in bias towards unity: the less precisely a risk factor is measured, the greater the bias. This effect has been described as ‘attenuation’, (Fuller &amp; Hidiroglou, 1978; Spearman, 1904) or more recently as ‘regression dilution bias’. (MacMahon et al., 1990) However, when correlated risk factors are measured with different degrees of imprecision, the adjusted relative risk associated with them can be biased towards or away from unity. (Greenland, 1980; Phillips &amp; Smith, 1991, 1992) When discussing limitations, authors may compare the study being presented with other studies in the literature in terms of validity, generalizability and precision. In this approach, each study can be viewed as contribution to the literature, not as a stand-alone basis for inference and action. (Poole et al., 2003) Surprisingly, the discussion of important limitations of a study is sometimes omitted from published reports. A survey of authors who had published original research articles in The Lancet found that important weaknesses of the study were reported by the investigators in the survey questionnaires, but not in the published article. (Horton, 2002; Vandenbroucke et al., 2007) Example “Since the prevalence of counseling increases with increasing levels of obesity, our estimates may overestimate the true prevalence. Telephone surveys also may overestimate the true prevalence of counseling. Although persons without telephones have similar levels of overweight as persons with telephones, persons without telephones tend to be less educated, a factor associated with lower levels of counseling in our study. Also, of concern is the potential bias caused by those who refused to participate as well as those who refused to respond to questions about weight. Furthermore, because data were collected cross-sectionally, we cannot infer that counseling preceded a patient’s attempt to lose weight.” (Galuska et al., 1999; Vandenbroucke et al., 2007) Field-specific guidance Anti-microbial stewardship programs (Tacconelli et al., 2016) - Provide description of sources of selection bias, including infection control measures, audit and confounding Infectious disease molecular epidemiology (Field et al., 2014) - Consider alternative explanations for ﬁndings when transmission chains are being investigated, and report the consistency between molecular and epidemiological evidence Neonatal infections (Fitchett et al., 2016) - Discuss sources of recruitment bias, particularly regarding the period of time shortly after birth. State source of denominator data and discuss possible related Seroepidemiologic studies for influenza (Horby et al., 2017) - Discuss limitations and strengths of the study with reference to Table 1 Resources Do you know of any good guidance or resources related to this item? Suggest them via comments below, Twitter, GitHub, or e-mail. References "],
["discussion-interpretation-20.html", "Discussion: Interpretation (20) Explanation Example Field-specific guidance Resources", " Discussion: Interpretation (20) The items from STROBE state that you should report: - Give a cautious overall interpretation of results considering objectives, limitations, multiplicity of analyses, results from similar studies, and other relevant evidence Some key items to consider adding: - Give an interpretation of results in terms of a priori biological plausibility Explanation The heart of the discussion section is the interpretation of a study’s results. Over-interpretation is common and human: even when we try hard to give an objective assessment, reviewers often rightly point out that we went too far in some respects. When interpreting results, authors should consider the nature of the study on the discovery to verification continuum and potential sources of bias, including loss to follow-up and non-participation (see also items 9, 12 and 19). Due consideration should be given to confounding (item 16a), the results of relevant sensitivity analyses, and to the issue of multiplicity and subgroup analyses (item 17). Authors should also consider residual confounding due to unmeasured variables or imprecise measurement of confounders. For example, socioeconomic status (SES) is associated with many health outcomesand often differs between groups being compared. Variables used to measure SES (income, education, or occupation) are surrogates for other undefined and unmeasured exposures, and the true confounder will by definition be measured with error. (Kaufman et al., 1997) Authors should address the real range of uncertainty in estimates, which is larger than the statistical uncertainty reflected in confidence intervals. The latter do not take into account other uncertainties that arise from a study’s design, implementation, and methods of measurement. (Greenland, 1990) To guide thinking and conclusions about causality, some may find criteria proposed by Bradford Hill in 1965 helpful. (Hill, 1965) How strong is the association with the exposure? Did it precede the onset of disease? Is the association consistently observed in different studies and settings? Is there supporting evidence from experimental studies, including laboratory and animal studies? How specific is the exposure’s putative effect, and is there a dose-response relationship? Is the association biologically plausible? These criteria should not, however, be applied mechanically. For example, some have argued that relative risks below 2 or 3 should be ignored.(Tabues, 1995; Temple, 1999) This is a reversal of the point by Cornfield et al about the strength of large relative risks (see item 12b). (Cornfield et al., 1959) Although a causal effect is more likely with a relative risk of 9, it does not follow that one below 3 is necessarily spurious. For instance, the small increase in the risk of childhood leukemia after intrauterine irradiation is credible because it concerns an adverse effect of a medical procedure for which no alternative explanations are obvious.(Greenberg &amp; Shuster, 1985) Moreover, the carcinogenic effects of radiation are well established. The doubling in the risk of ovarian cancer associated with eating 2 to 4 eggs per week is not immediately credible, since dietary habits are associated with a large number of lifestyle factors as well as SES. (Kushi et al., 1999) In contrast, the credibility of much debated epidemiologic findings of a difference in thrombosis risk between different types of oral contraceptives was greatly enhanced by the differences in coagulation found in a randomized cross-over trial. (Kemmeren et al., 2004) A discussion of the existing external evidence, from different types of studies, should always be included, but may be particularly important for studies reporting small increases in risk. Further, authors should put their results in context with similar studies and explain how the new study affects the existing body of evidence, ideally by referring to a systematic review. Example “Any explanation for an association between death from myocardial infarction and use of second generation oral contraceptives must be conjectural. There is no published evidence to suggest a direct biologic mechanism, and there are no other epidemiologic studies with relevant results. (. . .) The increase in absolute risk is very small and probably applies predominantly to smokers. Due to the lack of corroborative evidence, and because the analysis is based on relatively small numbers, more evidence on the subject is needed. We would not recommend any change in prescribing practice on the strength of these results.” (Dunn et al., 2001; Vandenbroucke et al., 2007) Field-specific guidance Seroepidemiologic studies for influenza (Horby et al., 2017) - Discuss the interpretation of the results in the context of known or potential cross-reactivity Nutritional data (Lachat et al., 2016) - Report the nutritional relevance of the ﬁndings, given the complexity of diet or nutrition as an exposure Resources Do you know of any good guidance or resources related to this item? Suggest them via comments below, Twitter, GitHub, or e-mail. References "],
["discussion-generalizability-21.html", "Discussion: Generalizability (21) Explanation Example Field-specific guidance Resources", " Discussion: Generalizability (21) The items from STROBE state that you should report: - Discuss the generalizability (external validity) of the study results Explanation Generalizability, also called external validity or applicability, is the extent to which the results of a study can be applied to other circumstances.(Campbell, 1957) There is no external validity per se; the term is meaningful only with regard to clearly specified conditions.(Justice, 1999) Can results be applied to an individual, groups or populations that differ from those enrolled in the study with regard to age, sex, ethnicity, severity of disease, and co-morbid conditions? Are the nature and level of exposures comparable, and the definitions of outcomes relevant to another setting or population? Are data that were collected in longitudinal studies many years ago still relevant today? Are results from health services research in one country applicable to health systems in other countries? The question of whether the results of a study have external validity is often a matter of judgment that depends on the study setting, the characteristics of the participants, the exposures examined, and the outcomes assessed. Thus, it is crucial that authors provide readers with adequate information about the setting and locations, eligibility criteria, the exposures and how they were measured, the definition of outcomes, and the period of recruitment and follow-up. The degree of nonparticipation and the proportion of unexposed participants in whom the outcome develops are also relevant. Knowledge of the absolute risk and prevalence of the exposure, which will often vary across populations, are helpful when applying results to other settings and populations (see Box 7). (Vandenbroucke et al., 2007). Example “How applicable are our estimates to other HIV-1-infected patients? This is an important question because the accuracy of prognostic models tends to be lower when applied to data other than those used to develop them. We addressed this issue by penalising model complexity, and by choosing models that generalized best to cohorts omitted from the estimation procedure. Our database included patients from many countries from Europe and North America, who were treated in different settings. The range of patients was broad: men and women, from teenagers to elderly people were included, and the major exposure categories were well represented. The severity of immunodeficiency at baseline ranged from not measureable to very severe, and viral load from undetectable to extremely high.” (Egger et al., 2002; Vandenbroucke et al., 2007) Field-specific guidance Anti-microbial stewardship programs (Tacconelli et al., 2016) - Discuss study setting, type of hospital, local epidemiology for the generalisability Simulation-based research (Cheng et al., 2016) - Describe generalizability of simulation-based outcomes to patient-based outcomes (if applicable) Resources Do you know of any good guidance or resources related to this item? Suggest them via comments below, Twitter, GitHub, or e-mail. References "],
["other-funding.html", "Other: Funding Explanation Resources", " Other: Funding The items from STROBE state that you should report: - Give the source of funding and the role of the funders for the present study and, if applicable, for the original study on which the present article is based Explanation Some journals require authors to disclose the presence or absence of financial and other conflicts of interest.(International Committee of Medical Journal Editors, 1997; Krimsky &amp; Rothenberg, 2001) Several investigations show strong associations between the source of funding and the conclusions of research articles. (Bekelman et al., 2003; Davidson, 1986; stelfox1998; Lexchin et al., 2003) The conclusions in randomized trials recommended the experimental drug as the drug of choice much more often (odds ratio 5.3) if the trial was funded by for-profit organisations, even after adjustment for the effect size.(Als-Nielsen et al., 2003) Other studies document the influence of the tobacco and telecommunication industries on the research they funded.(Barnes &amp; Bero, 1998; barnes1996; Huss et al., 2007; Safer, 2002) There are also examples of undue influence when the sponsor is governmental or a nonprofit organization. Authors or funders may have conflicts of interest that influence any of the following: the design of the study (Safer, 2002); choice of exposures,(Aspinall &amp; Goodman, 1995; Safer, 2002) outcomes,(Chan et al., 2004) statistical methods, (Melander et al., 2003) and selective publication of outcomes (Chan et al., 2004) and studies. (Scherer et al., 2007) Consequently, the role of the funders should be described in detail: in what part of the study they took direct responsibility (eg, design, data collection, analysis, drafting of the manuscript, decision to publish).(International Committee of Medical Journal Editors, 1997) Other sources of undue influence include employers (eg, university administrators for academic researchers and government supervisors, especially political appointees, for government researchers), advisory committees, litigants, and special interest groups. Resources Do you know of any good guidance or resources related to this item? Suggest them via comments below, Twitter, GitHub, or e-mail. References "],
["additional-information.html", "Additional Information Concluding Remarks Field-specific guidance Resources", " Additional Information Describe informed consent proceduers and and approval from ethical committee(s) If ethical approval was not obtained, explain the reason why not (e.g., public health outbreak response/non-research designation) Report any special ethical considerations (e.g., recruitment of minors, children, nenoates, etc.) Specify whether data/samples were anonymous, anonymized, or identiﬁable Describe any quality standards used in the conduct of the research Provide information on how to access supplemental information, the study protocol, data collection tools, raw data, and/or code Describe any conﬂicts of interest, or lack thereof, for each author Describe the authors’ roles (CRediT and/or ICMJE criteria) Concluding Remarks STROBE Statement aims to provide helpful recommendations for reporting observational studies in epidemiology. Good reporting reveals the strengths and weaknesses of a study and facilitates sound interpretation and application of study results. The STROBE Statement may also aid in planning observational studies, and guide peer reviewers and editors in their evaluation of manuscripts. We wrote this explanatory article to discuss the importance of transparent and complete reporting of observational studies, to explain the rationale behind the different items included in the checklist, and to give examples from published articles of what we consider good reporting. We hope that the material presented here will assist authors and editors in using STROBE. We stress that STROBE and other recommendations on the reporting of research (Bossuyt et al., 2003; Moher et al., 2001; Stroup et al., 2000) should be seen as evolving documents that require continual assessment, refinement, and, if necessary, change.(Altman, 2001; Moher, 1998) For example, the CONSORT Statement for the reporting of parallel-group randomized trials was first developed in the mid 1990s.(Begg et al., 1996) Since then members of the group have met regularly to review the need to revise the recommendations; a revised version appeared in 2001 and a further version is in development. Similarly, the principles presented in this article and the STROBE checklist are open to change as new evidence and critical comments accumulate. The STROBE web site provides a forum for discussion and suggestions for improvements of the checklist, this explanatory document and information about the good reporting of epidemiological studies. Several journals ask authors to follow the STROBE Statement in their instructions to authors (see http://www.strobe-statement.org for current list). We invite other journals to adopt the STROBE Statement and contact us through our web site to let us know.The journals publishing the STROBE recommendations provide open access. The STROBE Statement is therefore widely accessible to the biomedical community.(Vandenbroucke et al., 2007) Field-specific guidance Simulation-based research (Cheng et al., 2016) - List simulator brand and if conflict of interest for intellectual property exists. Resources Do you know of any good guidance or resources related to this item? Suggest them via comments below, Twitter, GitHub, or e-mail. References "],
["about-the-author.html", "About the Author", " About the Author Melissa Sharp completed this project as part of her work as a Marie Skłodowska-Curie doctoral research fellow at The University of Split and University of Paris within the Methods in Research on Research (MiRoR) Project. Her PhD, funded by the European Union Horizon 2020 research and innovation program, focuses on the STrengthening the Reporting of OBservational studies in Epidemiology (STROBE) reporting guideline. It looks into micro- and macro-level facilitators and barriers that influence the use of STROBE and reporting guidelines like it. She previously earned a Masters in Public Health in Epidemiology with a Graduate Certificate in Public Health Informatics from Columbia University Mailman School of Public Health and a Bachelor of Science in Psychology and Minor in Women and Gender Studies from Michigan State University. For more information such as CV, research interests, and contact information, please visit her website. STROBE Statement Acknowledgments : We are grateful to Gerd Antes, Kay Dickersin, Shah Ebrahim and Richard Lilford for supporting the STROBE Initiative. We are grateful to the following institutions that have hosted working meetings: Institute of Social and Preventive Medicine (ISPM), University of Bern, Switzerland; Department of Social Medicine, University of Bristol, UK; London School of Hygiene &amp; Tropical Medicine, London, UK; Nordic Cochrane Centre, Copenhagen, Denmark; and Centre for Statistics in Medicine, Oxford, UK. We are grateful to four anonymous reviewers who provided helpful comments on a previous draft of this paper. Contributors to the STROBE Initiative : The following persons have contributed to the content and elaboration of the STROBE Statement: Douglas G. Altman, Maria Blettner, Paolo Boffetta, Hermann Brenner, Geneviève Chêne, Cyrus Cooper, George Davey-Smith, Erik von Elm, Matthias Egger, France Gagnon, Peter C. Gøtzsche, Philip Greenland, Sander Greenland, Claire Infante-Rivard, John Ioannidis, Astrid James, Giselle Jones, Bruno Ledergerber, Julian Little, Margaret May, David Moher, Hooman Momen, Alfredo Morabia, Hal Morgenstern, Cynthia D. Mulrow, Fred Paccaud, Stuart J. Pocock, Charles Poole, Martin Röösli, Dietrich Rothenbacher, Kenneth Rothman, Caroline Sabin, Willi Sauerbrei, Lale Say, James J. Schlesselman, Jonathan Sterne, Holly Syddall, Jan P. Vandenbroucke, Ian White, Susan Wieland, Hywel Williams, Guang Yong Zou. (Vandenbroucke et al., 2007) References "],
["faq.html", "Frequently Asked Questions", " Frequently Asked Questions How can I contribute? There are three main ways that you can contribute. If you know RMarkdown and GitHub you can contribute directly via GitHub pull requests. Basically, navigate to the Rmd file that you want to change, edit the content, and submit the changes for approval. The repository owner, Melissa Sharp, will choose to integrate your comments by merging the changes into a new version. Each page should also be set up with a Disqus comment section where you can share any comments, concerns, or questions. If you don’t have a Disqus account already, you may need to make one prior to commenting. Lastly, the main author is reachable via e-mail or Twitter. When contact is made via these mechanisms it will be reported as such in the documentation. How is the book merged/compiled? The book uses a “Merge and Knit” approach which runs all code chunks in all chapters in the same R session. This allows objects created in previous chapters to be used in later chapters. (https://bookdown.org/yihui/bookdown/new-session.html) Why are the pages blank when I try to knit the book? If there is an issue in your page’s code, the book will appear to continue processing the pages afterwards but they will be blank and 0kb. Find the error in the last page that contains information and fix it. Then you should be able to reknit and the other pages will show up. Can I suggest a resource/reference? Similar to editing other files in the repository, you can propose edits to the .bib file. After a reference is added to the bib file, the reference can then be cited in the Rmd files. Each citation has a key which is composed of: @ and a citation identifier (e.g., @ name year). Common types of additions are: @ article, book, misc (like websites), and techreport. Note: Please do not use non-English characters if you are editing the .bib file. In the R Markdown files, citations go inside square brackets and are separated by semicolons. In text, citations should be written as: TEXT TEXT [ @ smith2001; @ smith2002, ch. 1 ] A minus sign ( - ) before the @ will suppress mention of the author in the citation. This can be useful when the author is already mentioned in the text. (e.g., Research from Smith et al. found… ) Can I download the references? Yes! You can download the .bib file if you would like and import it into your reference software manager. I’m having difficulties formatting the text The basics of text formatting in RMarkdown can be found here: https://bookdown.org/yihui/bookdown/markdown-syntax.html "],
["code-of-conduct.html", "Code of Conduct", " Code of Conduct Our Pledge In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation. Our Standards Examples of behavior that contributes to creating a positive environment include: Using welcoming and inclusive language Being respectful of differing viewpoints and experiences Gracefully accepting constructive criticism Focusing on what is best for the community Showing empathy towards other community members Examples of unacceptable behavior by participants include: The use of sexualized language or imagery and unwelcome sexual attention or advances Trolling, insulting/derogatory comments, and personal or political attacks Public or private harassment Publishing others’ private information, such as a physical or electronic address, without explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting Our Responsibilities Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior. Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful. Scope This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers. Enforcement Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the project team at melissaksharp@gmail.com. All complaints will be reviewed and investigated and will result in a response that is deemed necessary and appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately. Project maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project’s leadership. Attribution This Code of Conduct is adapted from the Contributor Covenant homepage, version 1.4, available at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html For answers to common questions about this code of conduct, see https://www.contributor-covenant.org/faq "],
["general-resources.html", "General Resources Writing Resources Teaching Epidemiology Statistics and Coding Resources", " General Resources Rothman, K. J., Greenland, S., &amp; Lash, T. L. (2008). Modern Epidemiology. Lippincott Williams &amp; Wilkins. (Rothman et al., 2008) Boston University Schol of Public Health. MPH Online Learning Modules. Retrieved February 13, 2020, from http://sphweb.bumc.bu.edu/otlt/MPH-Modules/Menu/index.html (Boston University School of Public Health, n.d.) Johns Hopkins Bloomberg School of Public Health. Fundamentals of Epidemiology I : Lecture Materials. In JHSPHOPEN coursewear. Retrieved January 27, 2020, from http://ocw.jhsph.edu/index.cfm/go/viewCourse/course/FundEpi/coursePage/lectureNotes/ (Johns Hopkins Bloomberg School of Public Health, 2020) Writing Resources Writing Aid Tool - Lachat, C. (2019). Contribute to carllachat/WritingAidTool development by creating an account on GitHub. https://github.com/carllachat/WritingAidTool original-date: 2019-02-07T17:29:24Z (Lachat, 2019) - Hawwash, D., Sharp, M. K., Argaw, A., Kolsteren, P., &amp; Lachat, C. (2019). Usefulness of applying research reporting guidelines as Writing Aid software: A crossover randomised controlled trial. BMJ Open, 9(11). https://doi.org/10.1136/bmjopen-2019-030943 (Hawwash et al., 2019) Others - Perneger, T. V., &amp; Hudelson, P. M. (2004). Writing a research article: Advice to beginners. International Journal for Quality in Health Care, 16(3), 191–192. https://doi.org/10.1093/intqhc/mzh053 (Perneger &amp; Hudelson, 2004) Teaching Epidemiology Trichopolous, D. (Ed.). (2010). Teaching epidemiology: A guide for teachers in epidemiology, public health and clinical medicine. Oxford University Press. https://www.amazon.co.uk/Teaching-Epidemiology-Teachers-Clinical-Medicine/dp/0199239479 (Trichopolous, 2010) Keyes, K. M., &amp; Galea, S. (2014). Current Practices in Teaching Introductory Epidemiology: How We Got Here, Where to Go. American Journal of Epidemiology, 180(7), 661–668. https://doi.org/10.1093/aje/kwu219 (Keyes &amp; Galea, 2014) Statistics and Coding Datamethods Discussion Forum. Retrieved February 13, 2020, from https://discourse.datamethods.org/ (“Datamethods Discussion Forum,” 2020) Stack Overflow - Where Developers Learn, Share, &amp; Build Careers. In Stack Overflow. Retrieved February 13, 2020, from https://stackoverflow.com/ (“Stack Overflow - Where Developers Learn, Share, &amp; Build Careers,” 2020) Resources Do you know of any good guidance or resources related to this item? Suggest them via comments below, Twitter, GitHub, or e-mail. "]
]
